# doc_sync/providers/buildin_ai.py
import requests
from typing import Dict, Optional, Tuple, List
from datetime import datetime
from urllib.parse import urlparse, parse_qs
import json
import logging
import re
import sys
import os
import time

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ path –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

from providers.base import DocumentProvider

logger = logging.getLogger(__name__)

class BuildinProvider(DocumentProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è Buildin.ai —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Google Drive –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    
    def __init__(self, auth_config: Dict):
        super().__init__(auth_config)
        self.total_blocks_to_process = 0
        self.blocks_processed = 0
        self.start_time = None
        self.show_progress = auth_config.get('show_progress', True)
    
    def setup_auth(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è Buildin.ai"""
        self.bot_token = self.auth_config.get('bot_token')
        if not self.bot_token:
            raise ValueError("bot_token is required for Buildin provider")
        
        self.base_url = "https://api.buildin.ai/v1"
        
        self.session = requests.Session()
        self.session.headers.update({
            "Authorization": f"Bearer {self.bot_token}",
            "Content-Type": "application/json",
            "Accept": "application/json"
        })
        
        # –û–ø—Ü–∏—è –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è Google Drive –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        self.include_gdrive_content = self.auth_config.get('include_gdrive_content', False)
        
        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –æ–ø—Ü–∏—è, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Google Drive –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        self.gdrive_provider = None
        if self.include_gdrive_content:
            gdrive_auth = self.auth_config.get('gdrive_auth_config')
            if gdrive_auth:
                try:
                    from providers.google_docs import GoogleDocsProvider
                    self.gdrive_provider = GoogleDocsProvider(gdrive_auth)
                    logger.info("Google Drive provider initialized for content inclusion")
                except Exception as e:
                    logger.warning(f"Failed to initialize Google Drive provider: {e}")
                    self.include_gdrive_content = False
        
        logger.info(f"Buildin provider initialized with base URL: {self.base_url}")      

    def _update_progress(self, increment: int = 1):
        """–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä"""
        if not self.show_progress:
            return
        
        if increment > 0:
            self.blocks_processed += increment
    
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ–∂–∏–¥–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if self.blocks_processed > self.total_blocks_to_process:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ–∂–∏–¥–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å –∑–∞–ø–∞—Å–æ–º
            self.total_blocks_to_process = self.blocks_processed + 10
    
        # –†–∞—Å—á–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        if self.total_blocks_to_process > 0:
            percentage = min(100.0, (self.blocks_processed / self.total_blocks_to_process * 100))
        else:
            percentage = 0
    
        # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏
        elapsed_time = time.time() - self.start_time if self.start_time else 0
        time_str = f"{elapsed_time:.1f}s"
    
        # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω–æ–π
        bar_length = 30
        filled = int(bar_length * min(1.0, self.blocks_processed / self.total_blocks_to_process)) if self.total_blocks_to_process > 0 else 0
        bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)
    
        # –í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        print(f"\r Processing: [{bar}] {self.blocks_processed}/{self.total_blocks_to_process} ({percentage:.1f}%) - {time_str}", end='', flush=True)

    def _count_total_blocks(self, page_id: str, count_nested: bool = True) -> int:
        """–ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        total = 0
        has_more = True
        start_cursor = None
        blocks_with_children = []
        child_pages = []
    
        # –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥ - —Å—á–∏—Ç–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –±–ª–æ–∫–∏
        while has_more:
            params = {'page_size': 100}
            if start_cursor:
                params['start_cursor'] = start_cursor
        
            try:
                response = self.session.get(
                    f"{self.base_url}/blocks/{page_id}/children",
                    params=params
                )
            
                if response.status_code != 200:
                    break
            
                data = response.json()
                blocks = data.get('results', [])
                total += len(blocks)
            
                # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–ª–æ–∫–∞—Ö
                for block in blocks:
                    block_type = block.get('type')
                
                    # –ï—Å–ª–∏ —ç—Ç–æ –¥–æ—á–µ—Ä–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∏ –≤–∫–ª—é—á–µ–Ω fetch_child_pages
                    if block_type == 'child_page' and self.auth_config.get('fetch_child_pages', False):
                        child_pages.append(block.get('id'))
                        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è preview (5 –±–ª–æ–∫–æ–≤ + —Å–≤–æ–π—Å—Ç–≤–∞)
                        total += 6
                
                    # –°–æ–±–∏—Ä–∞–µ–º –±–ª–æ–∫–∏ —Å has_children –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö
                    elif block.get('has_children') and count_nested:
                        blocks_with_children.append(block.get('id'))
            
                has_more = data.get('has_more', False)
                start_cursor = data.get('next_cursor')
            
                # –ó–∞—â–∏—Ç–∞ –æ—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
                if total > 5000:
                    break
                
            except Exception as e:
                logger.warning(f"Error counting blocks: {e}")
                break
    
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏ (toggle, lists –∏ —Ç.–¥.)
        if count_nested and blocks_with_children:
            # –î–ª—è –±–æ–ª—å—à–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –±–µ—Ä–µ–º –≤—ã–±–æ—Ä–∫—É
            sample_size = min(10, len(blocks_with_children))
            sample = blocks_with_children[:sample_size]
        
            nested_count = 0
            for block_id in sample:
                try:
                    response = self.session.get(f"{self.base_url}/blocks/{block_id}/children")
                    if response.status_code == 200:
                        data = response.json()
                        nested_count += len(data.get('results', []))
                except:
                    pass
        
            # –≠–∫—Å—Ç—Ä–∞–ø–æ–ª–∏—Ä—É–µ–º –¥–ª—è –≤—Å–µ—Ö –±–ª–æ–∫–æ–≤ —Å –¥–µ—Ç—å–º–∏
            if sample_size > 0:
                avg_nested = nested_count / sample_size
                estimated_nested = int(avg_nested * len(blocks_with_children))
                total += estimated_nested
    
        return total

    def extract_page_id(self, url: str) -> str:
        """–ò–∑–≤–ª–µ—á—å ID —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ URL"""
        # –£–±–∏—Ä–∞–µ–º —è–∫–æ—Ä—å –µ—Å–ª–∏ –µ—Å—Ç—å
        if '#' in url:
            url = url.split('#')[0]
        
        if '/' not in url:
            # –í–µ—Ä–æ—è—Ç–Ω–æ, —ç—Ç–æ —É–∂–µ ID
            return url
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ URL
        if 'buildin.ai' in url:
            parts = url.rstrip('/').split('/')
            if len(parts) > 0:
                # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å URL –∫–∞–∫ ID
                return parts[-1]
        
        raise ValueError(f"Cannot extract page ID from URL: {url}")
    
    def _extract_google_urls(self, properties: Dict) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á—å Google Drive URL –∏–∑ —Å–≤–æ–π—Å—Ç–≤ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        google_urls = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ properties –Ω–µ None –∏ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º
        if not properties or not isinstance(properties, dict):
            return google_urls
        
        for prop_name, prop_value in properties.items():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ prop_value –Ω–µ None –∏ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º
            if not prop_value or not isinstance(prop_value, dict):
                continue
                
            prop_type = prop_value.get('type')
            if not prop_type:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º URL —Å–≤–æ–π—Å—Ç–≤–∞
            if prop_type == 'url':
                url = prop_value.get('url', '')
                if url and ('docs.google.com' in url or 'drive.google.com' in url):
                    google_urls.append({
                        'property_name': prop_name,
                        'url': url,
                        'type': self._detect_google_doc_type(url)
                    })
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º rich_text —Å–≤–æ–π—Å—Ç–≤–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å—Å—ã–ª–æ–∫
            elif prop_type == 'rich_text':
                rich_text_items = prop_value.get('rich_text')
                if rich_text_items and isinstance(rich_text_items, list):
                    for item in rich_text_items:
                        if isinstance(item, dict) and 'text' in item:
                            text_obj = item.get('text')
                            if isinstance(text_obj, dict):
                                text = text_obj.get('content', '')
                                # –ò—â–µ–º Google URLs –≤ —Ç–µ–∫—Å—Ç–µ
                                urls = re.findall(r'https?://(?:docs|drive)\.google\.com/[^\s]+', text)
                                for url in urls:
                                    google_urls.append({
                                        'property_name': prop_name,
                                        'url': url,
                                        'type': self._detect_google_doc_type(url)
                                    })
        
        return google_urls
   
    def _detect_google_doc_type(self, url: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø Google –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ URL"""
        if 'spreadsheets' in url:
            return 'spreadsheet'
        elif 'document' in url:
            return 'document'
        elif 'presentation' in url:
            return 'presentation'
        elif 'drive.google.com' in url:
            return 'file'
        return 'unknown'
    
    def _fetch_google_content(self, url: str, doc_type: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ Google –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        if not self.gdrive_provider:
            return ""
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —á–µ—Ä–µ–∑ Google Drive –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            content, metadata = self.gdrive_provider.fetch_content(url)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º HTML –≤ Markdown –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if not metadata.get('_is_markdown', False):
                try:
                    from converters import HTMLToMarkdownConverter
                    converter = HTMLToMarkdownConverter()
                    content = converter.convert(content)
                except ImportError:
                    # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä, –¥–µ–ª–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
                    content = re.sub(r'<[^>]+>', '', content)  # –£–¥–∞–ª—è–µ–º HTML —Ç–µ–≥–∏
                    content = content.strip()
            
            return content
            
        except Exception as e:
            logger.warning(f"Failed to fetch Google content from {url}: {e}")
            return f"*[–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ: {str(e)}]*"
    
    def fetch_content(self, url: str) -> Tuple[str, Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã Buildin"""
        page_id = self.extract_page_id(url)
    
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self.blocks_processed = 0
        self.start_time = time.time()
    
        if self.show_progress:
            print(f"\nüöÄ Fetching Buildin page: {page_id}")
            print("üìä Counting blocks...")
    
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        page_response = self.session.get(f"{self.base_url}/pages/{page_id}")
    
        if page_response.status_code != 200:
            raise Exception(f"Failed to fetch page: {page_response.status_code}, {page_response.text}")
    
        page_data = page_response.json()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ page_data –≤–∞–ª–∏–¥–Ω—ã–π
        if not page_data or not isinstance(page_data, dict):
            raise Exception(f"Invalid page data received for {page_id}")
    
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            'title': self._extract_title(page_data),
            'id': page_data.get('id'),
            'created_time': page_data.get('created_time'),
            'last_edited_time': page_data.get('last_edited_time'),
            'url': page_data.get('url', url)
        }

        # –î–û–ë–ê–í–ò–¢–¨: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ø–æ–ª–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        metadata['modified_time'] = page_data.get('last_edited_time')
    
        if self.show_progress:
            print(f"üìÑ Page: {metadata['title']}")
    
        # –ë—ã—Å—Ç—Ä—ã–π –ø–æ–¥—Å—á–µ—Ç –±–µ–∑ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö
        quick_count = self._count_total_blocks(page_id, count_nested=False)
    
        # –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –¥–µ–ª–∞–µ–º —Ç–æ—á–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç
        if quick_count < 5000:
            self.total_blocks_to_process = self._count_total_blocks(page_id, count_nested=True)
        else:
            # –î–ª—è –±–æ–ª—å—à–∏—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É
            self.total_blocks_to_process = quick_count
        
            # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–æ—á–µ—Ä–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å preview, –¥–æ–±–∞–≤–ª—è–µ–º –±–æ–ª—å—à–µ
            if self.auth_config.get('fetch_child_pages', False):
                # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: –∫–∞–∂–¥–∞—è –¥–æ—á–µ—Ä–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–æ–±–∞–≤–ª—è–µ—Ç ~5 –±–ª–æ–∫–æ–≤
                self.total_blocks_to_process = int(quick_count * 1.5)
    
        # –ú–∏–Ω–∏–º—É–º 1 –±–ª–æ–∫–æ–≤ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0
        self.total_blocks_to_process = max(1, self.total_blocks_to_process)
    
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ–ª—É—á–∞–µ–º properties
        properties = page_data.get('properties') or {}
        
        # –î–æ–±–∞–≤–ª—è–µ–º –±–ª–æ–∫–∏ –¥–ª—è —Å–≤–æ–π—Å—Ç–≤ –∏ Google docs –µ—Å–ª–∏ –µ—Å—Ç—å
        if properties and isinstance(properties, dict):
            props_to_process = len([p for p in properties if p.lower() not in ['title', 'name']])
            self.total_blocks_to_process += props_to_process
    
        if self.include_gdrive_content and properties:
            google_urls = self._extract_google_urls(properties)
            self.total_blocks_to_process += len(google_urls)
    
        if self.show_progress:
            if quick_count >= 5000:
                print(f"üì¶ Estimated items to process: ~{self.total_blocks_to_process}")
            else:
                print(f"üì¶ Total items to process: {self.total_blocks_to_process}")
            self._update_progress(0)  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
    
        # –ü–æ–ª—É—á–∞–µ–º –±–ª–æ–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ Markdown
        markdown_content = self._fetch_page_blocks_as_markdown(page_id, page_data)
    
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤–æ–π—Å—Ç–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        properties_markdown = ""
        if properties and isinstance(properties, dict):
            properties_markdown = self._properties_to_markdown(properties)
    
        # –ò–∑–≤–ª–µ–∫–∞–µ–º Google URLs –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –æ–ø—Ü–∏—è
        google_content = ""
        if self.include_gdrive_content and properties:
            google_urls = self._extract_google_urls(properties) if properties else []
            if google_urls:
                google_content = "\n\n## üîé –ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã\n\n"
                for doc_info in google_urls:
                    google_content += f"### üìÑ {doc_info['property_name']}\n\n"
                    google_content += f"**URL:** {doc_info['url']}\n"
                    google_content += f"**–¢–∏–ø:** {doc_info['type']}\n\n"
                
                    # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                    doc_content = self._fetch_google_content(doc_info['url'], doc_info['type'])
                    if doc_content:
                        google_content += "#### –°–æ–¥–µ—Ä–∂–∏–º–æ–µ:\n\n"
                        google_content += doc_content
                        google_content += "\n\n---\n\n"
                    else:
                        google_content += "*[–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ]*\n\n---\n\n"
                
                    self._update_progress(1)
    
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –≤—Å–µ –≤ Markdown
        full_markdown = ""
        if properties_markdown:
            full_markdown += f"## Properties\n\n{properties_markdown}\n\n---\n\n"
        full_markdown += markdown_content
        if google_content:
            full_markdown += google_content
    
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if self.show_progress:
            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –Ω–∞ 100%
            if self.blocks_processed != self.total_blocks_to_process:
                self.total_blocks_to_process = self.blocks_processed
                self._update_progress(0)
        
            elapsed = time.time() - self.start_time
            print(f"\n‚úÖ Completed in {elapsed:.1f}s")
    
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Å —Ñ–ª–∞–≥–æ–º, —á—Ç–æ —ç—Ç–æ —É–∂–µ Markdown
        return full_markdown, {**metadata, '_is_markdown': True}

    def _extract_title(self, page_data: Dict) -> str:
        """–ò–∑–≤–ª–µ—á—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ page_data –Ω–µ None –∏ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º
        if not page_data or not isinstance(page_data, dict):
            return 'Untitled'
            
        properties = page_data.get('properties')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ properties –Ω–µ None –∏ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º
        if not properties or not isinstance(properties, dict):
            return 'Untitled'
        
        # –ò—â–µ–º —Å–≤–æ–π—Å—Ç–≤–æ title –∏–ª–∏ Title
        for prop_name in ['title', 'Title', 'Name', 'name']:
            if prop_name in properties:
                prop = properties[prop_name]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ prop –Ω–µ None –∏ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º
                if prop and isinstance(prop, dict):
                    if prop.get('type') == 'title' and 'title' in prop:
                        title_array = prop.get('title')
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ title_array —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∏—Å–∫–æ–º
                        if isinstance(title_array, list):
                            for item in title_array:
                                if isinstance(item, dict) and 'text' in item:
                                    text_obj = item.get('text')
                                    if isinstance(text_obj, dict):
                                        content = text_obj.get('content', '')
                                        if content:
                                            return content
        
        return 'Untitled'
    
    def _properties_to_markdown(self, properties: Dict) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–π—Å—Ç–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ Markdown"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ properties –Ω–µ None –∏ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º
        if not properties or not isinstance(properties, dict):
            return ""
        
        markdown = ""
        
        for prop_name, prop_value in properties.items():
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º title, —Ç–∞–∫ –∫–∞–∫ –æ–Ω —É–∂–µ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
            if prop_name.lower() in ['title', 'name']:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ prop_value –Ω–µ None –∏ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º
            if not prop_value or not isinstance(prop_value, dict):
                continue
                
            prop_type = prop_value.get('type')
            if not prop_type:
                continue
                
            content = self._extract_property_content(prop_value, prop_type)
            
            if content:
                # –î–ª—è URL –¥–µ–ª–∞–µ–º –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏
                if prop_type == 'url':
                    markdown += f"**{prop_name}:** [{content}]({content})\n"
                else:
                    markdown += f"**{prop_name}:** {content}\n"
            
            self._update_progress(1)
        
        return markdown
    
    def _extract_property_content(self, prop_value: Dict, prop_type: str) -> str:
        """–ò–∑–≤–ª–µ—á—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑ —Å–≤–æ–π—Å—Ç–≤–∞"""
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ None –∏ —Ç–∏–ø
        if not prop_value or not isinstance(prop_value, dict):
            return ''
            
        if prop_type == 'rich_text':
            texts = []
            rich_text_items = prop_value.get('rich_text')
            if rich_text_items and isinstance(rich_text_items, list):
                for item in rich_text_items:
                    if isinstance(item, dict) and 'text' in item:
                        text_obj = item.get('text')
                        if isinstance(text_obj, dict):
                            content = text_obj.get('content', '')
                            if content:
                                texts.append(content)
            return ' '.join(texts)
        
        elif prop_type == 'select':
            select = prop_value.get('select')
            if select and isinstance(select, dict):
                return select.get('name', '')
            return ''
        
        elif prop_type == 'multi_select':
            items = prop_value.get('multi_select')
            if items and isinstance(items, list):
                names = []
                for item in items:
                    if isinstance(item, dict):
                        name = item.get('name', '')
                        if name:
                            names.append(name)
                return ', '.join(names)
            return ''
        
        elif prop_type == 'checkbox':
            checkbox_value = prop_value.get('checkbox')
            if checkbox_value is not None:
                return '‚úî' if checkbox_value else '‚úó'
            return ''
        
        elif prop_type == 'number':
            number = prop_value.get('number')
            return str(number) if number is not None else ''
        
        elif prop_type == 'date':
            date_obj = prop_value.get('date')
            if date_obj and isinstance(date_obj, dict):
                start = date_obj.get('start', '')
                end = date_obj.get('end', '')
                if end:
                    return f"{start} - {end}"
                return start
            return ''
        
        elif prop_type == 'url':
            return prop_value.get('url', '')
        
        elif prop_type == 'email':
            return prop_value.get('email', '')
        
        elif prop_type == 'phone_number':
            return prop_value.get('phone_number', '')
        
        elif prop_type == 'people':
            people = prop_value.get('people')
            if people and isinstance(people, list):
                names = []
                for person in people:
                    if isinstance(person, dict):
                        name = person.get('name', 'Unknown')
                        if name:
                            names.append(name)
                return ', '.join(names)
            return ''
        
        elif prop_type == 'files':
            files = prop_value.get('files')
            if files and isinstance(files, list):
                links = []
                for file in files:
                    if isinstance(file, dict):
                        name = file.get('name', 'File')
                        external = file.get('external')
                        if external and isinstance(external, dict):
                            url = external.get('url', '')
                            if url:
                                links.append(f"[{name}]({url})")
                        else:
                            links.append(name)
                return ', '.join(links)
            return ''
        
        return ''
    
    def _fetch_page_blocks_as_markdown(self, page_id: str, page_data: Dict) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –±–ª–æ–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ Markdown"""
        markdown = ""
        has_more = True
        start_cursor = None
        total_blocks = 0
        child_pages_count = 0
    
        while has_more:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            params = {'page_size': 100}
            if start_cursor:
                params['start_cursor'] = start_cursor
        
            # –ü–æ–ª—É—á–∞–µ–º –±–ª–æ–∫–∏
            response = self.session.get(
                f"{self.base_url}/blocks/{page_id}/children",
                params=params
            )
        
            if response.status_code != 200:
                logger.warning(f"Failed to fetch blocks: {response.status_code}")
                break
        
            data = response.json()
            blocks = data.get('results', [])
        
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –±–ª–æ–∫–∏ –≤ Markdown
            for block in blocks:
                block_type = block.get('type')
            
                # –°—á–∏—Ç–∞–µ–º –¥–æ—á–µ—Ä–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                if block_type == 'child_page':
                    child_pages_count += 1
            
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –±–ª–æ–∫ (–ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±–Ω–æ–≤–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏)
                block_markdown = self._block_to_markdown(block)
                if block_markdown:
                    markdown += block_markdown + "\n"
            
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–ª—è —ç—Ç–æ–≥–æ –±–ª–æ–∫–∞
                self._update_progress(1)
        
            total_blocks += len(blocks)
        
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é
            has_more = data.get('has_more', False)
            start_cursor = data.get('next_cursor')
        
            # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
            if not blocks:
                break
        
            if total_blocks > 10000:
                logger.warning(f"Reached limit of 10000 blocks, stopping")
                break
    
        # –ï—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –¥–æ—á–µ—Ä–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –¥–æ–±–∞–≤–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        if child_pages_count > 0 and child_pages_count == total_blocks:
            header = f"## –î–æ—á–µ—Ä–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ({child_pages_count})\n\n"
            markdown = header + markdown
    
        logger.info(f"Processed {total_blocks} blocks, including {child_pages_count} child pages")
    
        return markdown
    
    def _block_to_markdown(self, block: Dict, indent_level: int = 0, is_nested: bool = False) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –±–ª–æ–∫ –≤ Markdown"""
        block_type = block.get('type')
        indent = "  " * indent_level
    
        if block_type == 'paragraph':
            content = self._rich_text_to_markdown(block.get('paragraph', {}).get('rich_text', []))
            return f"{indent}{content}" if content else ""
    
        elif block_type == 'heading_1':
            content = self._rich_text_to_markdown(block.get('heading_1', {}).get('rich_text', []))
            return f"{indent}# {content}" if content else ""
    
        elif block_type == 'heading_2':
            content = self._rich_text_to_markdown(block.get('heading_2', {}).get('rich_text', []))
            return f"{indent}## {content}" if content else ""
    
        elif block_type == 'heading_3':
            content = self._rich_text_to_markdown(block.get('heading_3', {}).get('rich_text', []))
            return f"{indent}### {content}" if content else ""
    
        elif block_type == 'bulleted_list_item':
            content = self._rich_text_to_markdown(block.get('bulleted_list_item', {}).get('rich_text', []))
            result = f"{indent}- {content}" if content else ""
        
            # –ü–æ–ª—É—á–∞–µ–º –¥–æ—á–µ—Ä–Ω–∏–µ –±–ª–æ–∫–∏
            if block.get('has_children'):
                children = self._fetch_child_blocks(block.get('id'))
                for child in children:
                    child_markdown = self._block_to_markdown(child, indent_level + 1, is_nested=True)
                    if child_markdown:
                        result += "\n" + child_markdown
                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–∏ –±–ª–æ–∫–∏ –Ω–µ –±—ã–ª–∏ —É—á—Ç–µ–Ω—ã
                    if not is_nested:
                        self._update_progress(1)
        
            return result
    
        elif block_type == 'numbered_list_item':
            content = self._rich_text_to_markdown(block.get('numbered_list_item', {}).get('rich_text', []))
            result = f"{indent}1. {content}" if content else ""
        
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—á–µ—Ä–Ω–∏–µ –±–ª–æ–∫–∏
            if block.get('has_children'):
                children = self._fetch_child_blocks(block.get('id'))
                for child in children:
                    child_markdown = self._block_to_markdown(child, indent_level + 1, is_nested=True)
                    if child_markdown:
                        result += "\n" + child_markdown
                    if not is_nested:
                        self._update_progress(1)
        
            return result
    
        elif block_type == 'to_do':
            todo = block.get('to_do', {})
            checked = '[x]' if todo.get('checked') else '[ ]'
            content = self._rich_text_to_markdown(todo.get('rich_text', []))
            result = f"{indent}- {checked} {content}"
        
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—á–µ—Ä–Ω–∏–µ –±–ª–æ–∫–∏
            if block.get('has_children'):
                children = self._fetch_child_blocks(block.get('id'))
                for child in children:
                    child_markdown = self._block_to_markdown(child, indent_level + 1, is_nested=True)
                    if child_markdown:
                        result += "\n" + child_markdown
                    if not is_nested:
                        self._update_progress(1)
        
            return result
    
        elif block_type == 'toggle':
            content = self._rich_text_to_markdown(block.get('toggle', {}).get('rich_text', []))
            result = f"{indent}‚ñ∂ {content}"
        
            # –ü–æ–ª—É—á–∞–µ–º –¥–æ—á–µ—Ä–Ω–∏–µ –±–ª–æ–∫–∏ –¥–ª—è toggle
            if block.get('has_children'):
                children = self._fetch_child_blocks(block.get('id'))
                for child in children:
                    child_markdown = self._block_to_markdown(child, indent_level + 1, is_nested=True)
                    if child_markdown:
                        result += "\n" + child_markdown
                    if not is_nested:
                        self._update_progress(1)
        
            return result
    
        elif block_type == 'code':
            code_block = block.get('code', {})
            language = code_block.get('language', '')
            content = self._rich_text_to_markdown(code_block.get('rich_text', []))
            return f"{indent}```{language}\n{content}\n{indent}```"
    
        elif block_type == 'quote':
            content = self._rich_text_to_markdown(block.get('quote', {}).get('rich_text', []))
            result = f"{indent}> {content}"
        
            # Quote —Ç–æ–∂–µ –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –¥–æ—á–µ—Ä–Ω–∏–µ –±–ª–æ–∫–∏
            if block.get('has_children'):
                children = self._fetch_child_blocks(block.get('id'))
                for child in children:
                    child_markdown = self._block_to_markdown(child, indent_level + 1, is_nested=True)
                    if child_markdown:
                        result += "\n" + child_markdown
                    if not is_nested:
                        self._update_progress(1)
        
            return result
    
        elif block_type == 'callout':
            callout = block.get('callout', {})
            icon = callout.get('icon', {}).get('emoji', 'üí°')
            content = self._rich_text_to_markdown(callout.get('rich_text', []))
            result = f"{indent}> {icon} {content}"
        
            # Callout –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –¥–æ—á–µ—Ä–Ω–∏–µ –±–ª–æ–∫–∏
            if block.get('has_children'):
                children = self._fetch_child_blocks(block.get('id'))
                for child in children:
                    child_markdown = self._block_to_markdown(child, indent_level + 1, is_nested=True)
                    if child_markdown:
                        result += "\n" + child_markdown
                    if not is_nested:
                        self._update_progress(1)
        
            return result
    
        elif block_type == 'divider':
            return f"{indent}---"
    
        elif block_type == 'table':
            return self._table_to_markdown(block, indent_level)
    
        elif block_type == 'image':
            image = block.get('image', {})
            url = ''
            if 'external' in image:
                url = image['external'].get('url', '')
            elif 'file' in image:
                url = image['file'].get('url', '')
        
            caption = self._rich_text_to_markdown(image.get('caption', []))
            if url:
                result = f"{indent}![{caption or 'Image'}]({url})"
                if caption:
                    result += f"\n{indent}*{caption}*"
                return result
    
        elif block_type == 'video':
            video = block.get('video', {})
            url = ''
            if 'external' in video:
                url = video['external'].get('url', '')
            elif 'file' in video:
                url = video['file'].get('url', '')
        
            if url:
                return f"{indent}[Video]({url})"
    
        elif block_type == 'file':
            file = block.get('file', {})
            url = ''
            if 'external' in file:
                url = file['external'].get('url', '')
            elif 'file' in file:
                url = file['file'].get('url', '')
        
            caption = self._rich_text_to_markdown(file.get('caption', []))
            if url:
                return f"{indent}[{caption or 'File'}]({url})"
    
        elif block_type == 'bookmark':
            bookmark = block.get('bookmark', {})
            url = bookmark.get('url', '')
            caption = self._rich_text_to_markdown(bookmark.get('caption', []))
        
            if url:
                return f"{indent}[{caption or url}]({url})"
    
        elif block_type == 'embed':
            embed = block.get('embed', {})
            url = embed.get('url', '')
            if url:
                return f"{indent}[Embed]({url})"
    
        elif block_type == 'child_page':
            # –í Buildin API –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ—á–µ—Ä–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ data.title
            child_data = block.get('data') or {}
            title = child_data.get('title', 'Untitled') if child_data else 'Untitled'
            child_id = block.get('id', '')
        
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –ø–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ—á–µ—Ä–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            fetch_child_content = self.auth_config.get('fetch_child_pages', False)
            max_depth = self.auth_config.get('max_depth', 1)
        
            if fetch_child_content and indent_level < max_depth and child_id:
                try:
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—á–µ—Ä–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                    child_response = self.session.get(f"{self.base_url}/pages/{child_id}")
                    if child_response.status_code == 200:
                        child_page_data = child_response.json()
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ –≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                        if not child_page_data:
                            logger.warning(f"Empty response for child page {child_id}")
                            return f"{indent}- **{title}**"
                        
                        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                        if isinstance(child_page_data, dict):
                            child_title = self._extract_title(child_page_data)
                        else:
                            child_title = title
                    
                        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ—á–µ—Ä–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                        result = f"{indent}### üìÑ {child_title}\n\n"
                    
                        # –ü–æ–ª—É—á–∞–µ–º —Å–≤–æ–π—Å—Ç–≤–∞ –¥–æ—á–µ—Ä–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
                        if isinstance(child_page_data, dict):
                            child_properties = child_page_data.get('properties') or {}
                            child_props = self._properties_to_markdown(child_properties)
                            if child_props:
                                result += f"{indent}{child_props}\n"
                    
                        # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–ª–æ–∫–æ–≤ –¥–ª—è preview
                        preview_response = self.session.get(
                            f"{self.base_url}/blocks/{child_id}/children",
                            params={'page_size': 5}
                        )
                        if preview_response.status_code == 200:
                            preview_data = preview_response.json()
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å preview_data
                            if isinstance(preview_data, dict):
                                preview_blocks = preview_data.get('results', [])
                            
                                for preview_block in preview_blocks:
                                    # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–ª–æ–∫–∏ –¥–æ—á–µ—Ä–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                                    if preview_block.get('type') != 'child_page':  # –ò–∑–±–µ–≥–∞–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–π —Ä–µ–∫—É—Ä—Å–∏–∏
                                        preview_markdown = self._block_to_markdown(preview_block, indent_level + 1, is_nested=True)
                                        if preview_markdown:
                                            result += preview_markdown + "\n"
                                    if not is_nested:
                                        self._update_progress(1)
                            
                                if preview_data.get('has_more'):
                                    result += f"{indent}  *...–±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ –¥–æ—á–µ—Ä–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ...*\n"
                    
                        return result + "\n"
                    else:
                        logger.warning(f"Failed to fetch child page {child_id}: status {child_response.status_code}")
                        return f"{indent}- **{title}**"
                        
                except Exception as e:
                    logger.error(f"Error fetching child page content for {child_id}: {e}")
                    logger.debug(f"Block data: {block}")
                    return f"{indent}- **{title}**"
        
            # –ï—Å–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ, –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∫–∞–∫ —Å–ø–∏—Å–æ–∫
            return f"{indent}- **{title}**"
    
        elif block_type == 'table_row':
            # –≠—Ç–æ—Ç —Ç–∏–ø –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤ _table_to_markdown
            return ""
    
        return ""   
    def _fetch_child_blocks(self, block_id: str) -> list:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–æ—á–µ—Ä–Ω–∏–µ –±–ª–æ–∫–∏"""
        try:
            response = self.session.get(f"{self.base_url}/blocks/{block_id}/children")
            if response.status_code == 200:
                data = response.json()
                return data.get('results', [])
        except Exception as e:
            logger.warning(f"Failed to fetch child blocks for {block_id}: {e}")
        return []
    
    def _table_to_markdown(self, block: Dict, indent_level: int = 0) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –≤ Markdown"""
        table_id = block.get('id')
        if not table_id:
            return ""
        
        indent = "  " * indent_level
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
        response = self.session.get(f"{self.base_url}/blocks/{table_id}/children")
        if response.status_code != 200:
            return ""
        
        rows_data = response.json()
        rows = rows_data.get('results', [])
        
        if not rows:
            return ""
        
        markdown = ""
        
        for i, row in enumerate(rows):
            if row.get('type') == 'table_row':
                cells = row.get('table_row', {}).get('cells', [])
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Ç–∞–±–ª–∏—Ü—ã
                row_content = []
                for cell in cells:
                    content = self._rich_text_to_markdown(cell)
                    row_content.append(content)
                
                markdown += f"{indent}| " + " | ".join(row_content) + " |\n"
                
                # –ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
                if i == 0:
                    separator = ["-" * max(len(cell), 3) for cell in row_content]
                    markdown += f"{indent}| " + " | ".join(separator) + " |\n"
            
            self._update_progress(1)
        
        return markdown
    
    def _rich_text_to_markdown(self, rich_text_array) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å rich text –≤ Markdown"""
        if not rich_text_array:
            return ""
        
        markdown = ""
        
        for item in rich_text_array:
            if 'text' in item:
                content = item['text'].get('content', '')
                link = item['text'].get('link')
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                annotations = item.get('annotations', {})
                
                if annotations.get('bold'):
                    content = f"**{content}**"
                if annotations.get('italic'):
                    content = f"*{content}*"
                if annotations.get('strikethrough'):
                    content = f"~~{content}~~"
                if annotations.get('code'):
                    content = f"`{content}`"
                
                # –°—Å—ã–ª–∫–∞
                if link:
                    url = link.get('url', '')
                    content = f"[{content}]({url})"
                
                markdown += content
            
            elif 'mention' in item:
                mention = item['mention']
                mention_type = mention.get('type')
                
                if mention_type == 'page':
                    page_id = mention.get('page', {}).get('id', '')
                    markdown += f"[Page Reference](#{page_id})"
                elif mention_type == 'database':
                    db_id = mention.get('database', {}).get('id', '')
                    markdown += f"[Database Reference](#{db_id})"
                elif mention_type == 'user':
                    user = mention.get('user', {})
                    name = user.get('name', 'User')
                    markdown += f"@{name}"
                elif mention_type == 'date':
                    date = mention.get('date', {})
                    start = date.get('start', '')
                    markdown += f"{start}"
            
            elif 'equation' in item:
                expression = item['equation'].get('expression', '')
                markdown += f"${expression}$"
        
        return markdown
    
    def check_for_updates(self, url: str, last_modified: Optional[datetime]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        if not last_modified:
            return True
    
        try:
            from datetime import timezone
        
            page_id = self.extract_page_id(url)
        
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            response = self.session.get(f"{self.base_url}/pages/{page_id}")
        
            if response.status_code == 200:
                page_data = response.json()
                last_edited_time_str = page_data.get('last_edited_time')
            
                if last_edited_time_str:
                    # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è –∏–∑ ISO —Ñ–æ—Ä–º–∞—Ç–∞
                    last_edited_time = datetime.fromisoformat(
                        last_edited_time_str.replace('Z', '+00:00')
                    )
                
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º last_modified
                    if isinstance(last_modified, str):
                        last_modified = datetime.fromisoformat(last_modified.replace('Z', '+00:00'))
                
                    if last_modified.tzinfo is None:
                        last_modified = last_modified.replace(tzinfo=timezone.utc)
                    if last_edited_time.tzinfo is None:
                        last_edited_time = last_edited_time.replace(tzinfo=timezone.utc)
                
                    return last_edited_time > last_modified
        except Exception as e:
            logger.error(f"Error checking updates for {url}: {e}")
            return True
    
        return False