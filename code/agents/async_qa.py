# code/agents/async_qa.py

import asyncio
import aiofiles
import hashlib
import json
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Set
from dataclasses import dataclass, field
import tiktoken
from openai import AsyncOpenAI

import xml.etree.ElementTree as ET
from xml.dom import minidom

from user_manager import UserManager

from user_activity_logger import activity_logger
import logging

logger = logging.getLogger(__name__)

# reasoning_effort: "minimal", "low", "medium", "high"
# verbosity: "low", "medium", "high"

select_reasoning_effort = "minimal" 
select_verbosity = "low"

answer_reasoning_effort = "minimal"
answer_verbosity = "medium"

@dataclass
class CachedDocument:
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
    content: str
    summary: str
    last_modified: float
    token_count: int
    file_hash: str


@dataclass
class CacheEntry:
    """–ó–∞–ø–∏—Å—å –≤ –∫—ç—à–µ —Å –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
    document: Optional[CachedDocument] = None
    lock: asyncio.Lock = field(default_factory=asyncio.Lock)
    updating: bool = False


class AsyncDocumentQA:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""

    def _load_options(self) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–ø—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞ options_aifaq.json
    
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ–ø—Ü–∏—è–º–∏ —Å—Ç—Ä–∞–Ω–∏—Ü –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        try:
            options_path = self.base_dir / "options_aifaq.json"
        
            if not options_path.exists():
                logger.info(f"–§–∞–π–ª options_aifaq.json –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {self.base_dir}, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
                return {}
        
            with open(options_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data.get('pages', {}))} –æ–ø—Ü–∏–π —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ options_aifaq.json")
                return data
            
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ options_aifaq.json: {str(e)}")
            return {}
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ options_aifaq.json: {str(e)}")
            return {}

    async def reload_options(self):
        """
        –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –æ–ø—Ü–∏–∏ –∏–∑ options_aifaq.json
        –ü–æ–ª–µ–∑–Ω–æ –µ—Å–ª–∏ —Ñ–∞–π–ª –±—ã–ª –æ–±–Ω–æ–≤–ª–µ–Ω –≤–æ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã
        """
        async with self.options_lock:
            self.options_cache = self._load_options()
            logger.info("options_aifaq.json –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω")

    def get_document_options(self, filename: str) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –æ–ø—Ü–∏–∏ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö options_aifaq.json
    
        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ–ø—Ü–∏—è–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º page_id –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
            page_id = self.get_page_id_by_filename(filename)
        
            if not page_id:
                return {}
        
            # –ò—â–µ–º –æ–ø—Ü–∏–∏ –≤ –∫—ç—à–µ
            pages_options = self.options_cache.get("pages", {})
        
            if page_id in pages_options:
                return pages_options[page_id]
            
            return {}
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ–ø—Ü–∏–π –¥–ª—è {filename}: {str(e)}")
            return {}

    def get_document_metadata(self, filename: str) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –∫—ç—à–∞ —Å —É—á–µ—Ç–æ–º –æ–ø—Ü–∏–π
    
        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
        """
        try:
            if not self.local_pages_cache:
                return {}
        
            pages = self.local_pages_cache.get("pages", {})
        
            # –ò—â–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
            metadata = {}
            for page_id, page_info in pages.items():
                file_name = page_info.get("file_name", "")
                file_name_without_ext = file_name.replace('.md', '').replace('.txt', '').replace('.markdown', '')
            
                if file_name_without_ext == filename:
                    metadata = page_info.copy()  # –ö–æ–ø–∏—Ä—É–µ–º —á—Ç–æ–±—ã –Ω–µ –º–µ–Ω—è—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª
                    break
        
            # –ü—Ä–æ–±—É–µ–º –ø–æ –∫–ª—é—á—É –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏
            if not metadata and filename in pages:
                metadata = pages[filename].copy()
        
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ü–∏–∏ –∏–∑ options_aifaq.json –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            options = self.get_document_options(filename)
            if options:
                metadata.update(options)  # –û–ø—Ü–∏–∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—é—Ç –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ local_pages
            
            return metadata
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è {filename}: {str(e)}")
            return {}

    def __init__(self, config_path: str = "./config_qa.json", 
                 access_config_path: str = "./document_access.json"):
        self.config_path = config_path
        self.access_config_path = access_config_path
        self.config = self._load_config()
        self.access_config = self._load_access_config()
        
        self.user_manager = UserManager()

        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç OpenAI
        self.client = AsyncOpenAI(api_key=self.config["api_key"])
        
        # –ü—É—Ç–∏
        self.base_dir = Path(self.config["base_dir"])
        self.source_dir = Path(self.config["source_dir"])
        self.summary_dir = Path(self.config["summary_dir"])
        
        # –ö—ç—à –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–æ–±—â–∏–π –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)
        self.document_cache: Dict[str, CacheEntry] = {}
        self.cache_lock = asyncio.Lock()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–ø—Ü–∏–∏ –∏–∑ options_aifaq.json
        self.options_cache = self._load_options()
        self.options_lock = asyncio.Lock()  # –î–ª—è –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–µ
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º local_pages.json –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        self.local_pages_cache = self._load_local_pages()
        self.local_pages_lock = asyncio.Lock()  # –î–ª—è –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–µ
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç—ã –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        self.prompts_cache = self._load_prompts()
        self.prompts_lock = asyncio.Lock()  # –î–ª—è –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–µ
        
        # Encoding –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
        self.encoding = tiktoken.get_encoding("cl100k_base")
        
        # –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API
        self.api_semaphore = asyncio.Semaphore(self.config.get("max_concurrent_api_calls", 5))
        
        # –ü—É—Ç—å –∫ –ª–æ–≥-—Ñ–∞–π–ª—É –∑–∞–ø—Ä–æ—Å–æ–≤
        self.queries_log_path = self.base_dir / "queries_log.jsonl"
        self.queries_log_lock = asyncio.Lock()
    
    def _load_local_pages(self) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ local_pages.json –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—Ä–∞–Ω–∏—Ü –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        try:
            local_pages_path = self.base_dir / "local_pages.json"
            
            if not local_pages_path.exists():
                logger.warning(f"–§–∞–π–ª local_pages.json –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {self.base_dir}")
                return {}
            
            with open(local_pages_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data.get('pages', {}))} —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ local_pages.json")
                return data
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ local_pages.json: {str(e)}")
            return {}
    
    def _load_prompts(self) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ prompt_*.json –≤ base_dir
        
        Returns:
            –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
        """
        try:
            combined_prompts = {"pages": {}}
            
            # –ò—â–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã prompt_*.json
            prompt_files = list(self.base_dir.glob("prompt_*.json"))
            
            if not prompt_files:
                logger.warning(f"–§–∞–π–ª—ã prompt_*.json –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {self.base_dir}")
                return combined_prompts
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
            for prompt_file in prompt_files:
                try:
                    with open(prompt_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        pages = data.get("pages", {})
                        combined_prompts["pages"].update(pages)
                        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(pages)} –ø—Ä–æ–º–ø—Ç–æ–≤ –∏–∑ {prompt_file.name}")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {prompt_file.name}: {str(e)}")
                    continue
            
            total_prompts = len(combined_prompts["pages"])
            logger.info(f"–í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {total_prompts} –ø—Ä–æ–º–ø—Ç–æ–≤ –∏–∑ {len(prompt_files)} —Ñ–∞–π–ª–æ–≤")
            return combined_prompts
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ prompt —Ñ–∞–π–ª–æ–≤: {str(e)}")
            return {"pages": {}}
    
    async def reload_local_pages(self):
        """
        –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ local_pages.json
        –ü–æ–ª–µ–∑–Ω–æ –µ—Å–ª–∏ —Ñ–∞–π–ª –±—ã–ª –æ–±–Ω–æ–≤–ª–µ–Ω –≤–æ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã
        """
        async with self.local_pages_lock:
            self.local_pages_cache = self._load_local_pages()
            logger.info("local_pages.json –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω")
    
    async def reload_prompts(self):
        """
        –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ prompt_*.json —Ñ–∞–π–ª–æ–≤
        –ü–æ–ª–µ–∑–Ω–æ –µ—Å–ª–∏ —Ñ–∞–π–ª—ã –±—ã–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤–æ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã
        """
        async with self.prompts_lock:
            self.prompts_cache = self._load_prompts()
            logger.info("–ü—Ä–æ–º–ø—Ç—ã –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    
    def get_document_url(self, filename: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç URL –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö local_pages
        
        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            
        Returns:
            URL –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        try:
            # –†–∞–±–æ—Ç–∞–µ–º —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            if not self.local_pages_cache:
                return None
            
            pages = self.local_pages_cache.get("pages", {})
            
            # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
            for page_id, page_info in pages.items():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º file_name (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .md)
                file_name = page_info.get("file_name", "")
                
                # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                file_name_without_ext = file_name.replace('.md', '').replace('.txt', '').replace('.markdown', '')
                
                if file_name_without_ext == filename:
                    return page_info.get("url")
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ file_name, –ø—Ä–æ–±—É–µ–º –ø–æ –∫–ª—é—á—É
            if filename in pages:
                return pages[filename].get("url")
                
            logger.debug(f"URL –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —Ñ–∞–π–ª–∞: {filename}")
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ URL –¥–ª—è {filename}: {str(e)}")
            return None    
    
    def get_page_id_by_filename(self, filename: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç page_id –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        
        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            
        Returns:
            page_id –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        try:
            if not self.local_pages_cache:
                return None
            
            pages = self.local_pages_cache.get("pages", {})
            
            # –ò—â–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ page_id
            for page_id, page_info in pages.items():
                file_name = page_info.get("file_name", "")
                file_name_without_ext = file_name.replace('.md', '').replace('.txt', '').replace('.markdown', '')
                
                if file_name_without_ext == filename:
                    return page_id
            
            # –ï—Å–ª–∏ filename —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å page_id
            if filename in pages:
                return filename
                
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ page_id –¥–ª—è {filename}: {str(e)}")
            return None
    
    def get_add_prompt(self, filename: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç add_prompt –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ —Ñ–∞–π–ª–æ–≤ prompt_*.json
        
        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            
        Returns:
            add_prompt –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º page_id –¥–æ–∫—É–º–µ–Ω—Ç–∞
            page_id = self.get_page_id_by_filename(filename)
            
            if not page_id:
                logger.debug(f"page_id –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —Ñ–∞–π–ª–∞: {filename}")
                return None
            
            # –ò—â–µ–º –ø—Ä–æ–º–ø—Ç –≤ –∫—ç—à–µ
            prompts_pages = self.prompts_cache.get("pages", {})
            
            if page_id in prompts_pages:
                add_prompt = prompts_pages[page_id].get("add_prompt")
                if add_prompt:
                    logger.debug(f"–ù–∞–π–¥–µ–Ω add_prompt –¥–ª—è {filename} (page_id: {page_id})")
                    return add_prompt
            
            logger.debug(f"add_prompt –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {filename} (page_id: {page_id})")
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ add_prompt –¥–ª—è {filename}: {str(e)}")
            return None
    
    def get_all_document_urls(self) -> Dict[str, str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –∏—Ö URL
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å {filename: url}
        """
        result = {}
        
        if not self.local_pages_cache:
            return result
        
        pages = self.local_pages_cache.get("pages", {})
        
        for page_id, page_info in pages.items():
            file_name = page_info.get("file_name", "")
            if file_name:
                file_name_without_ext = file_name.replace('.md', '').replace('.txt', '').replace('.markdown', '')
                url = page_info.get("url")
                if url:
                    result[file_name_without_ext] = url
        
        return result
    
    async def log_query_and_documents(
        self,
        user_id: int,
        query: str,
        selected_documents: List[str],
        selection_time: float,
        has_add_prompt: bool = False,
        metadata: Dict[str, Any] = None
    ):
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ª–æ–≥–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            selected_documents: –°–ø–∏—Å–æ–∫ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            selection_time: –í—Ä–µ–º—è –≤—ã–±–æ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            has_add_prompt: –ë—ã–ª –ª–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω add_prompt
            metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        """
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø–∏—Å—å –ª–æ–≥–∞
            log_entry = {
                "timestamp": datetime.now().isoformat(),
                "user_id": user_id,
                "query": query,
                "selected_documents": selected_documents,
                "documents_count": len(selected_documents),
                "selection_time": round(selection_time, 3),
                "has_add_prompt": has_add_prompt,
                "selection_model": self.config.get("selection_model", "unknown")
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
            if metadata:
                log_entry["metadata"] = metadata
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
            documents_info = []
            for doc_name in selected_documents:
                doc_info = {
                    "filename": doc_name,
                    "url": self.get_document_url(doc_name),
                    "has_add_prompt": bool(self.get_add_prompt(doc_name))
                }
                metadata_doc = self.get_document_metadata(doc_name)
                if metadata_doc.get("title"):
                    doc_info["title"] = metadata_doc["title"]
                documents_info.append(doc_info)
            
            log_entry["documents_info"] = documents_info
            
            # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª
            async with self.queries_log_lock:
                async with aiofiles.open(self.queries_log_path, 'a', encoding='utf-8') as f:
                    await f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
            
            logger.debug(f"Query logged for user {user_id}: {len(selected_documents)} documents selected")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}", exc_info=True)
    
    async def get_queries_log(
        self,
        user_id: Optional[int] = None,
        limit: Optional[int] = None,
        from_date: Optional[str] = None,
        to_date: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        –ß–∏—Ç–∞–µ—Ç –ª–æ–≥ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
        
        Args:
            user_id: –§–∏–ª—å—Ç—Ä –ø–æ ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            from_date: –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ ISO (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            to_date: –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ ISO (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π –ª–æ–≥–∞
        """
        try:
            if not self.queries_log_path.exists():
                return []
            
            queries = []
            
            async with aiofiles.open(self.queries_log_path, 'r', encoding='utf-8') as f:
                async for line in f:
                    try:
                        entry = json.loads(line.strip())
                        
                        # –§–∏–ª—å—Ç—Ä –ø–æ user_id
                        if user_id is not None and entry.get("user_id") != user_id:
                            continue
                        
                        # –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–∞–º
                        if from_date and entry.get("timestamp", "") < from_date:
                            continue
                        if to_date and entry.get("timestamp", "") > to_date:
                            continue
                        
                        queries.append(entry)
                        
                        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
                        if limit and len(queries) >= limit:
                            break
                            
                    except json.JSONDecodeError:
                        continue
            
            return queries
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –ª–æ–≥–∞ –∑–∞–ø—Ä–æ—Å–æ–≤: {str(e)}")
            return []
    
    async def get_queries_statistics(
        self,
        user_id: Optional[int] = None,
        days: int = 7
    ) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        try:
            from_date = (datetime.now() - timedelta(days=days)).isoformat()
            queries = await self.get_queries_log(user_id=user_id, from_date=from_date)
            
            if not queries:
                return {
                    "total_queries": 0,
                    "period_days": days,
                    "user_id": user_id
                }
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            total_queries = len(queries)
            documents_counter = {}
            avg_selection_time = sum(q.get("selection_time", 0) for q in queries) / total_queries
            queries_with_results = sum(1 for q in queries if q.get("documents_count", 0) > 0)
            queries_with_add_prompt = sum(1 for q in queries if q.get("has_add_prompt", False))
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            for query in queries:
                for doc in query.get("selected_documents", []):
                    documents_counter[doc] = documents_counter.get(doc, 0) + 1
            
            # –¢–æ–ø –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            top_documents = sorted(
                documents_counter.items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]
            
            return {
                "total_queries": total_queries,
                "period_days": days,
                "user_id": user_id,
                "queries_with_results": queries_with_results,
                "queries_with_add_prompt": queries_with_add_prompt,
                "avg_selection_time": round(avg_selection_time, 3),
                "avg_documents_per_query": round(
                    sum(q.get("documents_count", 0) for q in queries) / total_queries, 2
                ),
                "top_documents": [
                    {"document": doc, "count": count}
                    for doc, count in top_documents
                ],
                "unique_documents_used": len(documents_counter)
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}")
            return {}
    
    async def process_question(self, question: str, user_id: int, verbose: bool = True) -> str:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    
        Args:
            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_id: Telegram ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            verbose: –í—ã–≤–æ–¥–∏—Ç—å –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ—Ü–µ—Å—Å–µ
        
        Returns:
            –û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∏ URL
        """
        try:
            start_time = time.time()
        
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è –≤ –Ω–∞—á–∞–ª–æ –∑–∞–ø—Ä–æ—Å–∞
            current_datetime = datetime.now().strftime("%d.%m.%Y %H:%M")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ —á–µ—Ä–µ–∑ UserManager
            user_info_str = ""
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º UserManager –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                user_data = await self.user_manager.get_user(str(user_id))
            
                if user_data:
                    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
                    # –£—á–∏—Ç—ã–≤–∞–µ–º, —á—Ç–æ –≤ UserManager –µ—Å—Ç—å –ø–æ–ª–µ company –≤–º–µ—Å—Ç–æ patronymic
                    str_fio = f"{user_data.get('surname', '')} {user_data.get('name', '')}".strip()
                    if str_fio:
                        str_fio += ","
                
                    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–ø–∞–Ω–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
                    str_company = user_data.get('company', '').strip()
                    if str_company:
                        str_company = f"–ö–æ–º–ø–∞–Ω–∏—è: {str_company},"
                
                    str_pos_dept = []
                    if user_data.get('position', '').strip():
                        str_pos_dept.append(user_data.get('position', '').strip())
                    if user_data.get('department', '').strip():
                        str_pos_dept.append(user_data.get('department', '').strip())
                    str_pos = "/".join(str_pos_dept)
                    if str_pos:
                        str_pos += ","
                
                    str_eml = user_data.get('email', '').strip()
                    if str_eml:
                        str_eml += ","
                
                    str_tlg = f"Telegram: @{user_data.get('telegram_username', '')}" if user_data.get('telegram_username') else ""
                
                    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —á–∞—Å—Ç–∏ –≤–º–µ—Å—Ç–µ
                    usr_info_parts = [str_fio, str_company, str_pos, str_eml, str_tlg]
                    usr_info = " ".join(part for part in usr_info_parts if part).strip()
                
                    if usr_info:
                        user_info_str = f"\n[–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: {usr_info}]"
                                                    
            except Exception as e:
                logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ {user_id}: {str(e)}")
                if verbose:
                    print(f"[WARNING] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: {str(e)}")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å —Å –¥–∞—Ç–æ–π, –≤—Ä–µ–º–µ–Ω–µ–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
            question_with_datetime = f"[–¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞ –∏ –≤—Ä–µ–º—è: {current_datetime}]{user_info_str}\n\n{question}"
        
            # 1. –í—ã–±–∏—Ä–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            selection_start = time.time()
            selected_files = await self.select_relevant_documents(question_with_datetime, user_id)
            selection_time = time.time() - selection_start

            if not selected_files or selected_files == "NONE":
                if verbose:
                    print(f"[INFO] –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    print(f"[TIME] –í—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {selection_time:.2f}—Å")
                    print(f"[MODEL] –ú–æ–¥–µ–ª—å –≤—ã–±–æ—Ä–∞: {self.config.get('selection_model')}")
                return "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å."
        
            # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            if verbose:
                print(f"\n[INFO] –í—ã–±—Ä–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:")
                for i, file in enumerate(selected_files, 1):
                    url = self.get_document_url(file)
                    url_info = f" ({url[:50]}...)" if url else " (URL –Ω–µ –Ω–∞–π–¥–µ–Ω)"
                    add_prompt = self.get_add_prompt(file)
                    add_prompt_info = " [+prompt]" if add_prompt else ""
                    print(f"  {i}. {file}{url_info}{add_prompt_info}")
                print(f"[TIME] –í—Ä–µ–º—è –≤—ã–±–æ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {selection_time:.2f}—Å")
                print(f"[MODEL] –ú–æ–¥–µ–ª—å –≤—ã–±–æ—Ä–∞: {self.config.get('selection_model')}")
        
            # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∏ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            asyncio.create_task(
                self.log_query_and_documents(
                    user_id=user_id,
                    query=question,  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ –¥–∞—Ç—ã
                    selected_documents=selected_files,
                    selection_time=selection_time,
                    has_add_prompt=False,  # –ü–æ–∫–∞ –Ω–µ –∑–Ω–∞–µ–º, –æ–±–Ω–æ–≤–∏–º –ø–æ–∑–∂–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    metadata={
                        "query_with_datetime": question_with_datetime,
                        "current_datetime": current_datetime
                    }
                )
            )
        
            # 2. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            context_start = time.time()
            result = await self.prepare_context(selected_files, question_with_datetime)
            context = result["context"]
            filename = result["filename"]
        
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ –æ–ø—Ü–∏–∏ add_files
            additional_context = ""
            additional_files_used = []
        
            if filename:
                # –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ü–∏–∏ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                doc_options = self.get_document_options(filename)
            
                if doc_options and "add_files" in doc_options:
                    add_files_list = doc_options["add_files"]
                    if verbose:
                        print(f"[INFO] –ù–∞–π–¥–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è {filename}: {add_files_list}")
                
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–∂–¥—ã–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
                    for add_file_id in add_files_list:
                        try:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º—É —Ñ–∞–π–ª—É
                            if self.check_document_access(user_id, add_file_id):
                                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
                                add_doc = await self.load_document(add_file_id)
                            
                                if add_doc:
                                    additional_context += f"\n\n=== –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {add_file_id} ===\n{add_doc.content}"
                                    additional_files_used.append(add_file_id)
                                
                                    if verbose:
                                        print(f"[INFO] –î–æ–±–∞–≤–ª–µ–Ω –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª: {add_file_id}")
                            else:
                                if verbose:
                                    print(f"[WARNING] –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º—É —Ñ–∞–π–ª—É: {add_file_id}")
                                
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ {add_file_id}: {str(e)}")
                            if verbose:
                                print(f"[ERROR] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª {add_file_id}: {str(e)}")
        
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º
            if additional_context:
                context = context + additional_context
                if verbose:
                    print(f"[INFO] –î–æ–±–∞–≤–ª–µ–Ω–æ {len(additional_files_used)} –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É")

            # –ü–æ–ª—É—á–∞–µ–º add_prompt –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            add_prompt = None
            if filename:
                add_prompt = self.get_add_prompt(filename)

            context_time = time.time() - context_start
        
            if verbose:
                print(f"[TIME] –í—Ä–µ–º—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {context_time:.2f}—Å")
                if add_prompt:
                    print(f"[INFO] –ü—Ä–∏–º–µ–Ω–µ–Ω add_prompt –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {add_prompt[:100]}...")
                if additional_files_used:
                    print(f"[INFO] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã: {', '.join(additional_files_used)}")
        
            # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º add_prompt
            answer_start = time.time()

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å —Å add_prompt –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
            final_question = question_with_datetime
            if add_prompt:
                final_question = f"{add_prompt}\n\n{question_with_datetime}"

            answer = await self.generate_answer(final_question, context, user_id)
            answer_time = time.time() - answer_start
        
            total_time = time.time() - start_time
        
            if verbose:
                print(f"[TIME] –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {answer_time:.2f}—Å")
                print(f"[MODEL] –ú–æ–¥–µ–ª—å –æ—Ç–≤–µ—Ç–∞: {self.config.get('answer_model')}")
                print(f"[TIME] –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_time:.2f}—Å")
                print("-" * 50)

            # –õ–æ–≥–∏—Ä—É–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            logger.info(f"QA Process completed for user {user_id}: total_time={total_time:.2f}s, files={len(selected_files)}, add_prompt={bool(add_prompt)}, additional_files={len(additional_files_used)}")
        
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º –∏ URL
            response = answer
        
            if filename:
                # –ü–æ–ª—É—á–∞–µ–º URL –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –∫—ç—à–∞
                doc_url = self.get_document_url(filename)
                doc_metadata = self.get_document_metadata(filename)
            
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ
                response += f"\n\nüìÑ –ò—Å—Ç–æ—á–Ω–∏–∫: {filename}"
            
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –µ—Å–ª–∏ –µ—Å—Ç—å
                if doc_metadata.get("title"):
                    response += f"\nüìã –î–æ–∫—É–º–µ–Ω—Ç: {doc_metadata['title']}"
            
                # –î–æ–±–∞–≤–ª—è–µ–º URL —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ report_url –Ω–µ —Ä–∞–≤–Ω–æ false
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é report_url = true (–µ—Å–ª–∏ –ø–æ–ª—è –Ω–µ—Ç)
                report_url = doc_metadata.get("report_url", True)
                if doc_url and report_url:
                    response += f"\nüîó URL: {doc_url}"
            
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
                if doc_metadata.get("last_modified"):
                    response += f"\nüìÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {doc_metadata['last_modified'][:10]}"
            
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è add_prompt
                if add_prompt:
                    response += f"\n‚öôÔ∏è –ü—Ä–∏–º–µ–Ω–µ–Ω—ã —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"
            
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
                if additional_files_used:
                    response += f"\nüìé –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: {', '.join(additional_files_used)}"
        
            return response
        
        except Exception as e:
            if verbose:
                print(f"[ERROR] –û—à–∏–±–∫–∞: {str(e)}")
            logger.error(f"Error in process_question for user {user_id}: {str(e)}", exc_info=True)
            return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"

    def log_ai_request(
        self,
        user_id: int,
        provider: str,
        model: str,
        request_type: str,
        prompt_tokens: int,
        completion_tokens: int,
        response_time: float,
        error: str = None
    ):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ AI –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã QA"""
        try:
            # –õ–æ–≥–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ activity_logger
            activity_logger.log_ai_request(
                user_id=str(user_id),
                provider=provider,
                model=model,
                input_tokens=prompt_tokens,
                output_tokens=completion_tokens,
                duration=response_time
            )
        
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            if error:
                logger.error(f"QA AI Error - User: {user_id}, Model: {model}, Type: {request_type}, Error: {error}")
            else:
                logger.info(f"QA AI Success - User: {user_id}, Model: {model}, Type: {request_type}, Time: {response_time:.2f}s")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è QA AI –∑–∞–ø—Ä–æ—Å–∞: {e}")

    def _load_config(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
        default_config = {}
        
        if Path(self.config_path).exists():
            with open(self.config_path, 'r', encoding='utf-8') as f:
                loaded = json.load(f)
                default_config.update(loaded)        
        
        return default_config
    
    def _load_access_config(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º"""
        if Path(self.access_config_path).exists():
            with open(self.access_config_path, 'r', encoding='utf-8') as f:
                return json.load(f)   
    
        return None
    
    def get_user_groups(self, user_id: int) -> Set[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ—Å—Ç–æ–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"""
        user_groups = set()
    
        groups = self.access_config.get("groups", {})
        for group_id, group_info in groups.items():
            users_in_group = group_info.get("users", [])
            # –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø—É—Å—Ç–æ–π - —ç—Ç–æ –ø—É–±–ª–∏—á–Ω–∞—è –≥—Ä—É–ø–ø–∞
            if not users_in_group or user_id in users_in_group:
                user_groups.add(group_id)
    
        return user_groups

    async def reload_access_config(self):
        """–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–æ—Å—Ç—É–ø–∞"""
        self.access_config = self._load_access_config()
    
    def get_user_documents(self, user_id: int) -> Set[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"""
        available_docs = set()
    
        # –ü–æ–ª—É—á–∞–µ–º –≥—Ä—É–ø–ø—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_groups = self.get_user_groups(user_id)
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º —á–µ—Ä–µ–∑ –≥—Ä—É–ø–ø—ã
        documents = self.access_config.get("documents", {})
        for doc_id, doc_info in documents.items():
            doc_groups = doc_info.get("access_groups", [])
        
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –≥—Ä—É–ø–ø –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≥—Ä—É–ø–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞
            if user_groups.intersection(doc_groups):
                available_docs.add(doc_id)
    
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—É–±–ª–∏—á–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤—Å–µ–º)
        public_docs = self.access_config.get("public_documents", [])
        for doc_id in public_docs:
            available_docs.add(doc_id)
    
        return available_docs
    
    def check_document_access(self, user_id: int, document_id: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–º–µ–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ—Å—Ç—É–ø –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É"""
        user_docs = self.get_user_documents(user_id)
        return document_id in user_docs

    def get_user_info(self, user_id: int) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –∏ –µ–≥–æ –¥–æ—Å—Ç—É–ø–∞—Ö"""
        user_groups = self.get_user_groups(user_id)
        user_documents = self.get_user_documents(user_id)
    
        # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥—Ä—É–ø–ø–∞—Ö
        groups_info = []
        for group_id in user_groups:
            group_data = self.access_config.get("groups", {}).get(group_id, {})
            groups_info.append({
                "id": group_id,
                "name": group_data.get("name", group_id),
                "description": group_data.get("description", "")
            })
    
        # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
        documents_info = []
        for doc_id in user_documents:
            doc_data = self.access_config.get("documents", {}).get(doc_id, {})
            documents_info.append({
                "id": doc_id,
                "name": doc_data.get("name", doc_id)
            })
    
        return {
            "user_id": user_id,
            "groups": groups_info,
            "groups_count": len(groups_info),
            "documents": documents_info,
            "documents_count": len(documents_info)
        }

    def count_tokens(self, text: str) -> int:
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã"""
        return len(self.encoding.encode(text))
    
    def extract_body_content(self, content: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ ---"""
        parts = content.split('---', 1)
        if len(parts) > 1:
            return parts[1].strip()
        return content.strip()
    
    def calculate_file_hash(self, content: str) -> str:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ö—ç—à —Ñ–∞–π–ª–∞"""
        return hashlib.md5(content.encode()).hexdigest()
    
    def get_model_temperature(self, model: str, default: float = 0.7) -> float:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–ª—è –º–æ–¥–µ–ª–∏"""
        # –ú–æ–¥–µ–ª–∏, —Ç—Ä–µ–±—É—é—â–∏–µ temperature = 1
        fixed_temp_models = ["gpt-5", "gpt-5-mini", "gpt-5-nano", "o3", "o3-mini", "o4", "o4-mini", "o1-preview", "o1-mini", "o1"]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç—Ä–µ–±—É–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É
        for fixed_model in fixed_temp_models:
            if fixed_model in model.lower():
                return 1.0
        
        # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É
        return default
    
    async def get_file_info(self, filename: str) -> Optional[Tuple[Path, float]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø—É—Ç—å –∏ –≤—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞"""
        for ext in ['.txt', '.md', '.markdown']:
            file_path = self.source_dir / f"{filename}{ext}"
            if file_path.exists():
                stat = file_path.stat()
                return file_path, stat.st_mtime
        return None
    
    async def load_document(self, filename: str) -> Optional[CachedDocument]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –≤ –∫—ç—à–µ"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        file_info = await self.get_file_info(filename)
        if not file_info:
            return None
        
        file_path, last_modified = file_info
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –≤ –∫—ç—à–µ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        if filename not in self.document_cache:
            async with self.cache_lock:
                if filename not in self.document_cache:
                    self.document_cache[filename] = CacheEntry()
        
        cache_entry = self.document_cache[filename]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
        needs_update = (
            cache_entry.document is None or
            cache_entry.document.last_modified < last_modified
        )
        
        if not needs_update:
            return cache_entry.document
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç (—Å –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π)
        async with cache_entry.lock:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—â–µ —Ä–∞–∑ –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            if cache_entry.updating:
                # –ö—Ç–æ-—Ç–æ —É–∂–µ –æ–±–Ω–æ–≤–ª—è–µ—Ç, –∂–¥–µ–º
                while cache_entry.updating:
                    await asyncio.sleep(0.1)
                return cache_entry.document
            
            # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            if (cache_entry.document and 
                cache_entry.document.last_modified >= last_modified):
                return cache_entry.document
            
            cache_entry.updating = True
            
            try:
                # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
                async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                    content = await f.read()
                
                body = self.extract_body_content(content)
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—é–º–µ
                summary = await self.load_summary(filename, body)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
                cache_entry.document = CachedDocument(
                    content=body,
                    summary=summary,
                    last_modified=last_modified,
                    token_count=self.count_tokens(body),
                    file_hash=self.calculate_file_hash(body)
                )
                
                return cache_entry.document
                
            finally:
                cache_entry.updating = False
    
    async def load_summary(self, filename: str, content: str) -> str:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Ä–µ–∑—é–º–µ –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤–æ–µ"""
        summary_file = self.summary_dir / f"{filename}_summary.txt"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Ä–µ–∑—é–º–µ
        if summary_file.exists():
            async with aiofiles.open(summary_file, 'r', encoding='utf-8') as f:
                summary_content = await f.read()
                return summary_content
        
        # —Ä–µ–∑—é–º–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        return None
    
    async def select_relevant_documents(self, query: str, user_id: int) -> List[str]:
        """–í—ã–±–∏—Ä–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        start_time = time.time()

        # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        available_docs = self.get_user_documents(user_id)
        
        if not available_docs:
            return []
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = [self.load_document(doc) for doc in available_docs]
        documents = await asyncio.gather(*tasks)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º None –∏ —Å–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Ä–µ–∑—é–º–µ
        summaries = {}
        for doc_name, doc in zip(available_docs, documents):
            if doc:
                summaries[doc_name] = doc.summary
        
        if not summaries:
            return []

        #print(summaries)
            
        # –í—ã–±–∏—Ä–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–µ—Ä–µ–∑ API
        root = ET.Element("files")

        for filename, summary in summaries.items():
            file_el = ET.SubElement(root, "file")
            ET.SubElement(file_el, "name").text = filename
            ET.SubElement(file_el, "summary").text = summary

        # –°–æ–∑–¥–∞—ë–º XML —Å–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –∏ –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π UTF-8
        xml_bytes = ET.tostring(root, encoding="utf-8")
        xml_pretty = minidom.parseString(xml_bytes).toprettyxml(indent="  ", encoding="utf-8")

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
        files_list = xml_pretty.decode("utf-8")                    
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –∏ –≤—ã–±–µ—Ä–∏ —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –¢–û–ß–ù–û –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞.

–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: 
{query}

–î–û–°–¢–£–ü–ù–´–ï –§–ê–ô–õ–´ –° –ò–• –†–ï–ó–Æ–ú–ï:
{files_list}

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –í—ã–±–µ—Ä–∏ –¢–û–õ–¨–ö–û —Ç–µ —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –Ω–∞–ø—Ä—è–º—É—é –æ—Ç–≤–µ—á–∞—é—â—É—é –Ω–∞ –∑–∞–ø—Ä–æ—Å
2. –û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å–µ–∫—Ü–∏–∏ "üéØ –¢–û–ß–ù–û–ï –ù–ê–ó–ù–ê–ß–ï–ù–ò–ï" –∏ "‚ùå –ù–ï –ü–û–î–•–û–î–ò–¢ –î–õ–Ø" –≤ —Ä–µ–∑—é–º–µ
3. –£–ø–æ—Ä—è–¥–æ—á–∏ —Ñ–∞–π–ª—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (–ø–µ—Ä–≤—ã–π - —Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π)
4. –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç —Ç–æ—á–Ω–æ, –æ—Ç–≤–µ—Ç—å: NONE

–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û —Å–ø–∏—Å–∫–æ–º –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π), –ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É.
–í—ã–±—Ä–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏):"""


        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã
        prompt_tokens = self.count_tokens(prompt) + 10

        model = self.config.get("selection_model", "gpt-5-mini")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–ª—è –º–æ–¥–µ–ª–∏
        temperature = self.get_model_temperature(model, 0.1)
        
        #print(prompt) 
        
        async with self.api_semaphore:
            try:
                response = await self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "–í—ã–±–∏—Ä–∞–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã."},
                        {"role": "user", "content": prompt}
                    ],
                    reasoning_effort = self.config.get("select_reasoning_effort",select_reasoning_effort),
                    verbosity = self.config.get("select_verbosity",select_verbosity),
                    temperature=temperature
                )
                
                result = response.choices[0].message.content.strip()

                completion_tokens = self.count_tokens(result)
                response_time = time.time() - start_time
            
                # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
                self.log_ai_request(
                    user_id=user_id,
                    provider="openai",
                    model=model,
                    request_type="document_selection",
                    prompt_tokens=prompt_tokens,
                    completion_tokens=completion_tokens,
                    response_time=response_time
                )
                
                if result == "NONE":
                    return []
                
                selected = []
                for line in result.split('\n'):
                    line = line.strip()
                    if line and line in summaries:
                        selected.append(line)
                
                return selected[:3]  # –ú–∞–∫—Å–∏–º—É–º 3 —Ñ–∞–π–ª–∞
                
            except Exception as e:
                response_time = time.time() - start_time
                self.log_ai_request(
                    user_id=user_id,
                    provider="openai",
                    model=model,
                    request_type="document_selection",
                    prompt_tokens=prompt_tokens,
                    completion_tokens=0,
                    response_time=response_time,
                    error=str(e)
                )
                return []
    
    async def prepare_context(self, selected_files: List[str], query: str) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        if not selected_files:
            return ""
        
        model = self.config.get("answer_model", "gpt-5")
        max_tokens = self.config["model_contexts"].get(model, 8192) - 3000
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        tasks = [self.load_document(doc) for doc in selected_files]
        documents = await asyncio.gather(*tasks)
        
        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = ""
        total_tokens = 0
        
        for filename, doc in zip(selected_files, documents):
            if not doc:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–ª–µ–∑–µ—Ç –ª–∏
            if total_tokens + doc.token_count > max_tokens:
                # –û–±—Ä–µ–∑–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
                available = max_tokens - total_tokens
                if available > 1000:
                    tokens = self.encoding.encode(doc.content)
                    truncated = self.encoding.decode(tokens[:available])
                    context += f"\n\n=== {filename} (—á–∞—Å—Ç–∏—á–Ω–æ) ===\n{truncated}"
                break
            else:
                context += f"\n\n=== {filename} ===\n{doc.content}"
                total_tokens += doc.token_count

                return {"context": context, "filename": filename} # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º –æ–¥–Ω–∏–º —Ñ–∞–π–ª–æ–º –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        return {"context": None, "filename": None}
    
    async def generate_answer(self, query: str, context: str, user_id: int = 0) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        start_time = time.time()

        if not context:
            return "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å."
        
        model = self.config.get("answer_model", "gpt-5")
        
        prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–î–æ–∫—É–º–µ–Ω—Ç—ã:{context}

–í–æ–ø—Ä–æ—Å: {query}

–û—Ç–≤–µ—Ç:"""
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã
        prompt_tokens = self.count_tokens(prompt) + 10

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–ª—è –º–æ–¥–µ–ª–∏
        temperature = self.get_model_temperature(model, 0.7)
        
        async with self.api_semaphore:
            try:
                response = await self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "–û—Ç–≤–µ—á–∞–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."},
                        {"role": "user", "content": prompt}
                    ],
                    reasoning_effort = self.config.get("answer_reasoning_effort", answer_reasoning_effort),
                    verbosity = self.config.get("answer_verbosity", answer_verbosity),
                    temperature=temperature
                )

                answer = response.choices[0].message.content.strip()

                completion_tokens = self.count_tokens(answer)
                response_time = time.time() - start_time
            
                # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
                self.log_ai_request(
                    user_id=user_id,
                    provider="openai",
                    model=model,
                    request_type="answer_generation",
                    prompt_tokens=prompt_tokens,
                    completion_tokens=completion_tokens,
                    response_time=response_time
                )
            
                return answer
                
            except Exception as e:

                response_time = time.time() - start_time
                self.log_ai_request(
                    user_id=user_id,
                    provider="openai",
                    model=model,
                    request_type="answer_generation",
                    prompt_tokens=prompt_tokens,
                    completion_tokens=0,
                    response_time=response_time,
                    error=str(e)
                )
                
                return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}"

    async def cleanup_cache(self):
        """–û—á–∏—â–∞–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –∫—ç—à"""
        current_time = time.time()
        ttl = self.config.get("cache_ttl_seconds", 300)
        
        async with self.cache_lock:
            to_remove = []
            for filename, entry in self.document_cache.items():
                if entry.document:
                    age = current_time - entry.document.last_modified
                    if age > ttl:
                        to_remove.append(filename)
            
            for filename in to_remove:
                del self.document_cache[filename]


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤:
"""
# –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø—Ä–æ—Å–æ–≤
queries = await qa_system.get_queries_log(limit=10)

# –ü–æ–ª—É—á–∏—Ç—å –∑–∞–ø—Ä–æ—Å—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
user_queries = await qa_system.get_queries_log(user_id=123456)

# –ü–æ–ª—É—á–∏—Ç—å –∑–∞–ø—Ä–æ—Å—ã –∑–∞ –ø–µ—Ä–∏–æ–¥
queries = await qa_system.get_queries_log(
    from_date="2025-01-01T00:00:00",
    to_date="2025-01-31T23:59:59"
)

# –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
stats = await qa_system.get_queries_statistics(days=7)
print(f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total_queries']}")
print(f"–¢–æ–ø –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats['top_documents']}")

# –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
user_stats = await qa_system.get_queries_statistics(user_id=123456, days=30)
"""