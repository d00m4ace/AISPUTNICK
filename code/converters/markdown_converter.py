# code/converters/markdown_converter.py
"""
–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä—ã —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –≤ Markdown
"""
import os
import asyncio
import logging
import tempfile
import subprocess
import shutil
from typing import Tuple, Optional, Any, List
from io import BytesIO
import pandas as pd
from PIL import Image
from converters.base_converter import FileConverter, ProgressCallback, CancelCheck

logger = logging.getLogger(__name__)


class MarkdownConverterManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–æ–≤ –≤ Markdown"""
    
    def __init__(self, ai_interface=None):
        self.ai_interface = ai_interface
        self.converters = [
            PDFConverter(ai_interface),
            ImageConverter(ai_interface),
            ExcelConverter(),
            CSVConverter(),
            DocumentConverter(),
            HTMLConverter(),
            PowerPointConverter()
        ]
    
    async def convert_to_markdown(
        self, 
        user_id: str,
        file_bytes: bytes, 
        filename: str,
        encoding: Optional[str] = None,
        progress_callback: Optional[ProgressCallback] = None,
        cancel_check: Optional[CancelCheck] = None
    ) -> Tuple[bool, str, str]:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –≤ Markdown –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
        Returns: (success, new_filename, markdown_content)
        """
        for converter in self.converters:
            if converter.supports(filename):
                kwargs = {}
                if encoding:
                    kwargs['encoding'] = encoding
                if progress_callback:
                    kwargs['progress_callback'] = progress_callback
                if cancel_check:
                    kwargs['cancel_check'] = cancel_check
                
                return await converter.convert(user_id, file_bytes, filename, **kwargs)
        
        return False, filename, ""
    
    def can_convert(self, filename: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–Ω–æ –ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª"""
        return any(conv.supports(filename) for conv in self.converters)


class HTMLConverter(FileConverter):
    """–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä HTML –≤ Markdown –∏—Å–ø–æ–ª—å–∑—É—è markdownify"""
    
    SUPPORTED_EXTENSIONS = {'.html', '.htm', '.xhtml'}
    
    def supports(self, filename: str) -> bool:
        ext = os.path.splitext(filename.lower())[1]
        return ext in self.SUPPORTED_EXTENSIONS
    
    async def convert(self, user_id: str, file_bytes: bytes, filename: str, **kwargs) -> Tuple[bool, str, str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç HTML –≤ Markdown"""
        base, _ = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        try:
            # –ü—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å markdownify
            try:
                from markdownify import markdownify
            except ImportError:
                logger.warning("markdownify –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥")
                return await self._convert_via_pandoc(file_bytes, filename)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É HTML
            encoding = kwargs.get('encoding', 'utf-8')
            try:
                html_content = file_bytes.decode(encoding)
            except UnicodeDecodeError:
                # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                for enc in ['utf-8', 'cp1251', 'latin-1', 'cp866']:
                    try:
                        html_content = file_bytes.decode(enc)
                        break
                    except UnicodeDecodeError:
                        continue
                else:
                    html_content = file_bytes.decode('utf-8', errors='replace')
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º HTML –≤ Markdown
            markdown_text = markdownify(
                html_content,
                heading_style="ATX",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º # –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                bullets="-",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º - –¥–ª—è —Å–ø–∏—Å–∫–æ–≤
                code_language="python",  # –Ø–∑—ã–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞
                strip=['script', 'style', 'meta', 'link'],  # –£–¥–∞–ª—è–µ–º —ç—Ç–∏ —Ç–µ–≥–∏
                wrap=True,
                wrap_width=80,
                convert=['a', 'b', 'blockquote', 'br', 'code', 'div', 'em', 
                        'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'hr', 'i', 
                        'img', 'li', 'ol', 'p', 'pre', 'strong', 'u', 'ul',
                        'table', 'thead', 'tbody', 'tr', 'th', 'td']
            )
            
            # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            markdown_text = self._clean_markdown(markdown_text)
            
            if markdown_text and markdown_text.strip():
                logger.info(f"HTML —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ markdownify: {filename}")
                return True, new_name, markdown_text
            else:
                logger.warning(f"markdownify –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è {filename}")
                return False, new_name, ""
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ HTML —á–µ—Ä–µ–∑ markdownify: {e}")
            # –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ pandoc –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
            return await self._convert_via_pandoc(file_bytes, filename)
    
    async def _convert_via_pandoc(self, file_bytes: bytes, filename: str) -> Tuple[bool, str, str]:
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ pandoc"""
        base, _ = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        if not shutil.which("pandoc"):
            logger.error("pandoc –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return False, new_name, ""
        
        try:
            with tempfile.TemporaryDirectory() as td:
                in_path = os.path.join(td, "input.html")
                out_path = os.path.join(td, "output.md")
                
                with open(in_path, "wb") as f:
                    f.write(file_bytes)
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º pandoc —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è —Ö–æ—Ä–æ—à–µ–≥–æ markdown
                subprocess.run(
                    ["pandoc", "-s", in_path, "--wrap=none", 
                     "--reference-links", "-t", "markdown", "-o", out_path],
                    check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE
                )
                
                with open(out_path, "r", encoding="utf-8", errors="replace") as f:
                    markdown_text = f.read()
            
            markdown_text = self._clean_markdown(markdown_text)
            logger.info(f"HTML —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ pandoc: {filename}")
            return True, new_name, markdown_text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ pandoc –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ HTML: {e}")
            return False, new_name, ""
    
    def _clean_markdown(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç markdown —Ç–µ–∫—Å—Ç"""
        import re
        
        # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
        lines = text.split('\n')
        lines = [line.rstrip() for line in lines]
        text = '\n'.join(lines)
        
        # –£–¥–∞–ª—è–µ–º HTML –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)
        
        # –£–¥–∞–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è HTML —Ç–µ–≥–∏
        text = re.sub(r'<[^>]+>', '', text)
        
        return text.strip()


class PowerPointConverter(FileConverter):
    """–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä PowerPoint –≤ Markdown –∏—Å–ø–æ–ª—å–∑—É—è pptx2md"""
    
    SUPPORTED_EXTENSIONS = {'.pptx', '.ppt'}
    
    def supports(self, filename: str) -> bool:
        ext = os.path.splitext(filename.lower())[1]
        return ext in self.SUPPORTED_EXTENSIONS
    
    async def convert(self, user_id: str, file_bytes: bytes, filename: str, **kwargs) -> Tuple[bool, str, str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç PowerPoint –≤ Markdown"""
        base, ext = os.path.splitext(filename)
        new_name = f"{base}.txt"
    
        # –î–ª—è .ppt —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–±—É–µ–º —Ç–æ–ª—å–∫–æ pandoc
        if ext.lower() == '.ppt':
            return await self._convert_via_pandoc(file_bytes, filename)
    
        # –°—Ä–∞–∑—É –∏—Å–ø–æ–ª—å–∑—É–µ–º python-pptx, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ
        return await self._convert_via_python_pptx(file_bytes, filename)
    
    async def _convert_via_python_pptx(self, file_bytes: bytes, filename: str) -> Tuple[bool, str, str]:
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ python-pptx"""
        base, _ = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        try:
            from pptx import Presentation
        except ImportError:
            logger.error("python-pptx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return await self._convert_via_pandoc(file_bytes, filename)
        
        try:
            prs = Presentation(BytesIO(file_bytes))
            markdown_lines = [f"# {filename}\n"]
            
            for slide_num, slide in enumerate(prs.slides, 1):
                markdown_lines.append(f"\n## –°–ª–∞–π–¥ {slide_num}\n")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö shape
                for shape in slide.shapes:
                    if hasattr(shape, "text") and shape.text:
                        text = shape.text.strip()
                        if text:
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø shape –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                            if shape.name.startswith("Title"):
                                markdown_lines.append(f"### {text}\n")
                            elif shape.name.startswith("Subtitle"):
                                markdown_lines.append(f"**{text}**\n")
                            else:
                                markdown_lines.append(f"{text}\n")
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
                    if shape.has_table:
                        markdown_lines.append("\n")
                        table = shape.table
                        
                        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
                        headers = []
                        for cell in table.rows[0].cells:
                            headers.append(cell.text.strip())
                        
                        if headers:
                            markdown_lines.append("| " + " | ".join(headers) + " |")
                            markdown_lines.append("| " + " | ".join(["---"] * len(headers)) + " |")
                            
                            # –°—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
                            for row in table.rows[1:]:
                                cells = []
                                for cell in row.cells:
                                    cells.append(cell.text.strip())
                                markdown_lines.append("| " + " | ".join(cells) + " |")
                        
                        markdown_lines.append("\n")
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É —Å–ª–∞–π–¥–∞–º–∏
                if slide_num < len(prs.slides):
                    markdown_lines.append("\n---\n")
            
            markdown_text = "\n".join(markdown_lines)
            
            if markdown_text.strip():
                logger.info(f"PowerPoint —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ python-pptx: {filename}")
                return True, new_name, markdown_text
            else:
                return False, new_name, ""
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PowerPoint —á–µ—Ä–µ–∑ python-pptx: {e}")
            return await self._convert_via_pandoc(file_bytes, filename)
    
    async def _convert_via_pandoc(self, file_bytes: bytes, filename: str) -> Tuple[bool, str, str]:
        """–ó–∞–ø–∞—Å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ pandoc"""
        base, ext = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        if not shutil.which("pandoc"):
            logger.error("pandoc –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return False, new_name, ""
        
        try:
            with tempfile.TemporaryDirectory() as td:
                in_path = os.path.join(td, f"input{ext}")
                out_path = os.path.join(td, "output.md")
                
                with open(in_path, "wb") as f:
                    f.write(file_bytes)
                
                subprocess.run(
                    ["pandoc", "-s", in_path, "--wrap=none", 
                     "-t", "markdown", "-o", out_path],
                    check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE
                )
                
                with open(out_path, "r", encoding="utf-8", errors="replace") as f:
                    markdown_text = f.read()
            
            logger.info(f"PowerPoint —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ pandoc: {filename}")
            return True, new_name, markdown_text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ pandoc –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PowerPoint: {e}")
            return False, new_name, ""


class ExcelConverter(FileConverter):
    """–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä Excel –≤ Markdown –∏—Å–ø–æ–ª—å–∑—É—è excel-to-markdown"""
    
    def supports(self, filename: str) -> bool:
        ext = os.path.splitext(filename.lower())[1]
        return ext in {'.xls', '.xlsx'}
    
    async def convert(self, user_id: str, file_bytes: bytes, filename: str, **kwargs) -> Tuple[bool, str, str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç Excel –≤ Markdown"""
        base, _ = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º excel-to-markdown –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
        result = await self._convert_via_excel_to_markdown(file_bytes, filename)
        if result[0]:
            return result
        
        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º pandas
        return await self._convert_via_pandas(file_bytes, filename)
    
    async def _convert_via_excel_to_markdown(self, file_bytes: bytes, filename: str) -> Tuple[bool, str, str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ excel-to-markdown"""
        base, ext = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ excel-to-markdown
        if not shutil.which("excel-to-markdown"):
            logger.debug("excel-to-markdown –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return False, new_name, ""
        
        try:
            with tempfile.TemporaryDirectory() as td:
                in_path = os.path.join(td, f"input{ext}")
                out_path = os.path.join(td, "output.md")
                
                with open(in_path, "wb") as f:
                    f.write(file_bytes)
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º excel-to-markdown
                subprocess.run(
                    ["excel-to-markdown", in_path, "-o", out_path],
                    check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE
                )
                
                with open(out_path, "r", encoding="utf-8", errors="replace") as f:
                    markdown_text = f.read()
            
            if markdown_text.strip():
                logger.info(f"Excel —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ excel-to-markdown: {filename}")
                return True, new_name, markdown_text
            else:
                return False, new_name, ""
                
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ excel-to-markdown: {e}")
            return False, new_name, ""
    
    async def _convert_via_pandas(self, file_bytes: bytes, filename: str) -> Tuple[bool, str, str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ pandas (fallback)"""
        base, _ = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        try:
            bio = BytesIO(file_bytes)
            xls = pd.ExcelFile(bio)
            out_parts = [f"# {filename}\n"]
            
            for sheet in xls.sheet_names:
                df = xls.parse(sheet, dtype=object)
                df = df.fillna("")
                
                out_parts.append(f"\n## {sheet}\n")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ª–∏—Å—Ç—É
                out_parts.append(f"*–°—Ç—Ä–æ–∫: {len(df)}, –°—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns)}*\n\n")
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ markdown —Ç–∞–±–ª–∏—Ü—É
                rows = [list(df.columns)] + df.values.tolist()
                out_parts.append(self._rows_to_markdown(rows))
                out_parts.append("\n")
            
            md = "\n".join(out_parts).strip() + "\n"
            logger.info(f"Excel —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ pandas: {filename}")
            return True, new_name, md
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ Excel —á–µ—Ä–µ–∑ pandas: {e}")
            return False, new_name, ""
    
    def _rows_to_markdown(self, rows: List[List[Any]]) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –≤ markdown-—Ç–∞–±–ª–∏—Ü—É"""
        if not rows:
            return ""
        
        str_rows = [[("" if c is None else str(c)) for c in r] for r in rows]
        header = str_rows[0]
        body = str_rows[1:] if len(str_rows) > 1 else []
        
        widths = [len(h) for h in header]
        for r in body:
            for j, cell in enumerate(r):
                if j < len(widths):
                    widths[j] = max(widths[j], len(cell))
                else:
                    widths.append(len(cell))
        
        def fmt_row(r):
            return "| " + " | ".join((r[i] if i < len(r) else "").ljust(widths[i]) for i in range(len(widths))) + " |"
        
        parts = [fmt_row(header)]
        parts.append("| " + " | ".join("-" * widths[i] for i in range(len(widths))) + " |")
        for r in body:
            parts.append(fmt_row(r))
        
        return "\n".join(parts)


class DocumentConverter(FileConverter):
    """–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ Word/RTF —á–µ—Ä–µ–∑ pandoc —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
    
    SUPPORTED_EXTENSIONS = {'.docx', '.doc', '.rtf', '.odt'}
    
    def supports(self, filename: str) -> bool:
        ext = os.path.splitext(filename.lower())[1]
        return ext in self.SUPPORTED_EXTENSIONS and shutil.which("pandoc") is not None
    
    async def convert(self, user_id: str, file_bytes: bytes, filename: str, **kwargs) -> Tuple[bool, str, str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –≤ Markdown —á–µ—Ä–µ–∑ pandoc"""
        base, ext = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        try:
            with tempfile.TemporaryDirectory() as td:
                in_path = os.path.join(td, f"input{ext}")
                out_path = os.path.join(td, "output.md")
                
                with open(in_path, "wb") as f:
                    f.write(file_bytes)
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã pandoc –¥–ª—è –ª—É—á—à–µ–≥–æ markdown
                pandoc_args = [
                    "pandoc",
                    "-s",  # standalone
                    in_path,
                    "--wrap=auto",  # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫
                    "--columns=128",  # —à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–∫–∏ 128 —Å–∏–º–≤–æ–ª–æ–≤
                    "--reference-links",  # —Å—Å—ã–ª–∫–∏ –≤ –∫–æ–Ω—Ü–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                    "-t", "markdown",  # –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç
                    "--extract-media", td,  # –∏–∑–≤–ª–µ—á—å –º–µ–¥–∏–∞ –≤ –ø–∞–ø–∫—É
                    "-o", out_path
                ]
                
                # –î–ª—è docx –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏
                if ext.lower() == '.docx':
                    pandoc_args.insert(2, "--track-changes=accept")  # –ø—Ä–∏–Ω—è—Ç—å –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
                
                result = subprocess.run(
                    pandoc_args,
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                if result.returncode != 0:
                    logger.warning(f"pandoc –≤–µ—Ä–Ω—É–ª –∫–æ–¥ {result.returncode}: {result.stderr}")
                
                with open(out_path, "r", encoding="utf-8", errors="replace") as f:
                    md = f.read()
            
            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ markdown
            md = self._postprocess_markdown(md)
            
            if md.strip():
                logger.info(f"–î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ pandoc: {filename}")
                return True, new_name, md
            else:
                logger.warning(f"pandoc –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è {filename}")
                return False, new_name, ""
            
        except subprocess.TimeoutExpired:
            logger.error(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {filename}")
            return False, new_name, ""
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ pandoc –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
            return False, new_name, ""
    
    def _postprocess_markdown(self, text: str) -> str:
        """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ markdown –ø–æ—Å–ª–µ pandoc"""
        import re
    
        # –£–¥–∞–ª—è–µ–º —Ä–∞–∑–º–µ—Ç–∫—É {.mark} –∏ –ø–æ–¥–æ–±–Ω—É—é
        text = re.sub(r'\[([^\]]+)\]\{[^}]+\}', r'\1', text)
        text = re.sub(r'\{\.[\w\-]+\}', '', text)
    
        # –£–¥–∞–ª—è–µ–º escape-—Å–∏–º–≤–æ–ª—ã –ø–µ—Ä–µ–¥ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏ markdown
        text = re.sub(r'\\([#*_\[\]()>"|])', r'\1', text)
    
        # –£–¥–∞–ª—è–µ–º –¥–≤–æ–π–Ω—ã–µ –æ–±—Ä–∞—Ç–Ω—ã–µ —Å–ª–µ—à–∏
        text = re.sub(r'\\\\', '', text)
    
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        text = re.sub(r'\n{3,}', '\n\n', text)
    
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
        lines = text.split('\n')
        lines = [line.rstrip() for line in lines]
        text = '\n'.join(lines)
    
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
        text = self._fix_tables(text)
    
        # –£–¥–∞–ª—è–µ–º –º–µ—Ç–∞-—Ç–µ–≥–∏ –≤ –Ω–∞—á–∞–ª–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        text = re.sub(r'^---\n.*?\n---\n', '', text, flags=re.DOTALL)
    
        # –£–¥–∞–ª—è–µ–º span-—Ç–µ–≥–∏ –∏ –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö
        text = re.sub(r'\[([^\]]+)\]\([^)]*\)', r'\1', text)
    
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ —Å–∫–æ–±–∫–∏ –≤–æ–∫—Ä—É–≥ —Ç–µ–∫—Å—Ç–∞
        text = re.sub(r'^\[(.+)\]$', r'\1', text, flags=re.MULTILINE)
    
        return text.strip()
    
    def _fix_tables(self, text: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü"""
        import re
    
        lines = text.split('\n')
        fixed_lines = []
        in_table = False
    
        for line in lines:
            if '|' in line:
                if not in_table:
                    in_table = True
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ
                if re.match(r'^[\s\|:\-]+$', line):
                    # –≠—Ç–æ —Å—Ç—Ä–æ–∫–∞-—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
                    parts = line.split('|')
                    parts = ['---' if p.strip() else '' for p in parts]
                    line = '|'.join(parts)
                fixed_lines.append(line)
            else:
                if in_table:
                    in_table = False
                fixed_lines.append(line)
    
        return '\n'.join(fixed_lines)


class CSVConverter(FileConverter):
    """–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä CSV –≤ Markdown"""
    
    def supports(self, filename: str) -> bool:
        return filename.lower().endswith('.csv')
    
    async def convert(self, user_id: str, file_bytes: bytes, filename: str, **kwargs) -> Tuple[bool, str, str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç CSV –≤ Markdown"""
        base, _ = os.path.splitext(filename)
        new_name = f"{base}.txt"
        encoding = kwargs.get('encoding', 'utf-8')
        
        try:
            bio = BytesIO(file_bytes)
            df = pd.read_csv(bio, encoding=encoding, dtype=object)
        except Exception:
            # –ü—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É
            import chardet
            result = chardet.detect(file_bytes)
            detected = result.get('encoding', 'utf-8')
            try:
                bio = BytesIO(file_bytes)
                df = pd.read_csv(bio, encoding=detected, dtype=object)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV: {e}")
                return False, new_name, ""
        
        df = df.fillna("")
        rows = [list(df.columns)] + df.values.tolist()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –º–µ—Ç–æ–¥ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        converter = ExcelConverter()
        md = f"# {filename}\n\n"
        md += f"*–°—Ç—Ä–æ–∫: {len(df)}, –°—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns)}*\n\n"
        md += converter._rows_to_markdown(rows) + "\n"
        
        return True, new_name, md

class PDFConverter(FileConverter):
    """–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä PDF –≤ Markdown"""
    
    def __init__(self, ai_interface=None):
        self.ai_interface = ai_interface
        self._markitdown = None
    
    def supports(self, filename: str) -> bool:
        return filename.lower().endswith('.pdf')
    
    def _get_markitdown(self):
        """Lazy –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MarkItDown"""
        if self._markitdown is None:
            try:
                from markitdown import MarkItDown
                self._markitdown = MarkItDown()
                logger.info("MarkItDown –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except ImportError:
                logger.warning("MarkItDown –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                return None
        return self._markitdown
    
    async def convert(self, user_id: str, file_bytes: bytes, filename: str, **kwargs) -> Tuple[bool, str, str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç PDF –≤ Markdown"""
        base, _ = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        progress_callback = kwargs.get('progress_callback')
        cancel_check = kwargs.get('cancel_check')
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º MarkItDown
        ok, _, md_text = await self._convert_via_markitdown(file_bytes, filename)
        if ok:
            return ok, new_name, md_text
        
        # –ó–∞—Ç–µ–º –ø—Ä–æ–±—É–µ–º OCR (–µ—Å–ª–∏ PDF —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
        ok, _, md_text = await self._convert_via_ocr(file_bytes, filename, progress_callback, cancel_check)
        if ok:
            return ok, new_name, md_text
        
        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –∏ –µ—Å—Ç—å AI - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if self.ai_interface:
            ok, _, md_text = await self._convert_via_images(
                user_id,
                file_bytes, filename, progress_callback, cancel_check
            )
        
        return ok, new_name, md_text
    
    async def _convert_via_markitdown(self, file_bytes: bytes, filename: str) -> Tuple[bool, str, str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —á–µ—Ä–µ–∑ MarkItDown"""
        base, _ = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        markitdown = self._get_markitdown()
        if not markitdown:
            return False, new_name, ""
        
        try:
            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp_file:
                tmp_file.write(file_bytes)
                tmp_path = tmp_file.name
            
            try:
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(None, markitdown.convert, tmp_path)
                
                if result and hasattr(result, 'text_content'):
                    markdown_text = result.text_content
                    if markdown_text and markdown_text.strip():
                        logger.info(f"PDF —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ MarkItDown: {filename}")
                        return True, new_name, markdown_text
            finally:
                try:
                    os.unlink(tmp_path)
                except:
                    pass
                    
        except Exception as e:
            logger.warning(f"MarkItDown –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å PDF: {e}")
        
        return False, new_name, ""
    
    async def _convert_via_ocr(self, file_bytes: bytes, filename: str, 
                               progress_callback: Optional[ProgressCallback] = None,
                               cancel_check: Optional[CancelCheck] = None) -> Tuple[bool, str, str]:
        """OCR –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö PDF —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º pytesseract"""
        base, _ = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        try:
            import pytesseract
            from PIL import Image
            from pdf2image import convert_from_bytes
        except ImportError as e:
            logger.debug(f"OCR –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã: {e}")
            return False, new_name, ""
        
        try:
            if progress_callback:
                await progress_callback("üîç –ü—Ä–æ–±—É—é OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ PDF...")
            
            logger.info(f"Attempting OCR for potential scanned PDF: {filename}")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            images = convert_from_bytes(file_bytes, dpi=150)
            total_pages = len(images)
            
            if progress_callback:
                await progress_callback(
                    f"üìä –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {total_pages}\n"
                    f"‚è≥ –ù–∞—á–∏–Ω–∞—é OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ...\n"
                    f"üí° –û—Ç–ø—Ä–∞–≤—å—Ç–µ /cancel_file_job –¥–ª—è –æ—Ç–º–µ–Ω—ã"
                )
            
            text_parts = []
            
            for i, image in enumerate(images, 1):
                if cancel_check and await cancel_check():
                    logger.info(f"OCR –æ—Ç–º–µ–Ω–µ–Ω–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {i}")
                    if progress_callback:
                        await progress_callback(
                            f"‚ö†Ô∏è OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ\n"
                            f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {i-1}/{total_pages}"
                        )
                    break
                
                if progress_callback:
                    await progress_callback(
                        f"üìÑ OCR —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {i}/{total_pages}\n"
                        f"{"‚ñì" * i}{"‚ñë" * (total_pages - i)} {i}/{total_pages}\n"
                        f"üí° /cancel_file_job –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏"
                    )
                
                try:
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º OCR —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä—É—Å—Å–∫–æ–≥–æ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤
                    text = pytesseract.image_to_string(image, lang='rus+eng')
                    if text and text.strip():
                        text_parts.append(f"## –°—Ç—Ä–∞–Ω–∏—Ü–∞ {i}\n\n{text.strip()}")
                        logger.info(f"OCR —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {i} —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞")
                except Exception as e:
                    logger.warning(f"OCR failed for page {i}: {e}")
                    # –ü—Ä–æ–±—É–µ–º —Ç–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫
                    try:
                        text = pytesseract.image_to_string(image)
                        if text and text.strip():
                            text_parts.append(f"## –°—Ç—Ä–∞–Ω–∏—Ü–∞ {i}\n\n{text.strip()}")
                            logger.info(f"OCR —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {i} —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ (—Ç–æ–ª—å–∫–æ eng)")
                    except:
                        pass
                
                if i < total_pages:
                    await asyncio.sleep(0.1)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
            
            if text_parts:
                full_text = f"# –î–æ–∫—É–º–µ–Ω—Ç: {filename}\n"
                full_text += f"–°—Ç—Ä–∞–Ω–∏—Ü —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {len(text_parts)} –∏–∑ {total_pages}\n"
                full_text += "---\n\n"
                full_text += "\n\n".join(text_parts)
                
                if progress_callback:
                    await progress_callback(
                        f"‚úÖ OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\n"
                        f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {len(text_parts)}/{total_pages}"
                    )
                
                logger.info(f"PDF —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω —á–µ—Ä–µ–∑ OCR: {len(text_parts)}/{total_pages} —Å—Ç—Ä–∞–Ω–∏—Ü")
                return True, new_name, full_text
                
        except ImportError:
            logger.debug("OCR –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã (pytesseract/pdf2image)")
        except Exception as e:
            logger.warning(f"OCR failed for {filename}: {e}")
            if progress_callback:
                await progress_callback(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ OCR: {str(e)}")
        
        return False, new_name, ""
    
    async def _convert_via_images(
        self, 
        user_id: str,
        file_bytes: bytes, 
        filename: str,
        progress_callback: Optional[ProgressCallback] = None,
        cancel_check: Optional[CancelCheck] = None
    ) -> Tuple[bool, str, str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç PDF —á–µ—Ä–µ–∑ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å—Ç—Ä–∞–Ω–∏—Ü —Å –ø–æ–º–æ—â—å—é AI"""
        base, _ = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        if not self.ai_interface:
            return False, new_name, ""
        
        try:
            from pdf2image import convert_from_bytes
        except ImportError:
            logger.error("pdf2image –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return False, new_name, ""
        
        try:
            if progress_callback:
                await progress_callback("üìÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é PDF —Ñ–∞–π–ª...")
            
            images = convert_from_bytes(file_bytes, dpi=150)
            total_pages = len(images)
            
            if progress_callback:
                await progress_callback(
                    f"üìä –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {total_pages}\n"
                    f"‚è≥ –ù–∞—á–∏–Ω–∞—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ...\n"
                    f"üí° –û—Ç–ø—Ä–∞–≤—å—Ç–µ /cancel_file_job –¥–ª—è –æ—Ç–º–µ–Ω—ã"
                )
            
            page_texts = []
            
            for i, img in enumerate(images):
                page_num = i + 1
                
                if cancel_check and await cancel_check():
                    logger.info(f"–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}")
                    if progress_callback:
                        await progress_callback(
                            f"‚ö†Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ\n"
                            f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {len(page_texts)}/{total_pages}"
                        )
                    break
                
                if progress_callback:
                    await progress_callback(
                        f"üìÑ –†–∞—Å–ø–æ–∑–Ω–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num}/{total_pages}\n"
                        f"{"‚ñì" * page_num}{"‚ñë" * (total_pages - page_num)} {page_num}/{total_pages}\n"
                        f"üí° /cancel_file_job –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏"
                    )
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ bytes
                buffer = BytesIO()
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                width, height = img.size
                if width > 2000 or height > 2000:
                    if width > height:
                        new_width = 2000
                        new_height = int(height * (2000 / width))
                    else:
                        new_height = 2000
                        new_width = int(width * (2000 / height))
                    img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                
                img.save(buffer, format='PNG')
                img_bytes = buffer.getvalue()
                
                prompt = (
                    f"–†–∞—Å–ø–æ–∑–Ω–∞–π –≤–µ—Å—å —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num} –∏–∑ {total_pages}. "
                    f"–í–µ—Ä–Ω–∏ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≤–∫–ª—é—á–∞—è —Ç–∞–±–ª–∏—Ü—ã, —Å–ø–∏—Å–∫–∏ –∏ –≤—Å–µ –¥–µ—Ç–∞–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown. "
                    f"–ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç, –Ω–∞–ø–∏—à–∏ —Ç–æ–ª—å–∫–æ: '–¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω'"
                )
                
                try:
                    result = await self.ai_interface.process_image(user_id, img_bytes, prompt)
                    if result and result.strip() and "–¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω" not in result:
                        page_texts.append(f"## –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}\n\n{result.strip()}")
                        logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
                    if progress_callback:
                        await progress_callback(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}, –ø—Ä–æ–ø—É—Å–∫–∞—é...")
                
                if i < len(images) - 1:
                    await asyncio.sleep(0.3)
            
            if page_texts:
                full_text = f"# –î–æ–∫—É–º–µ–Ω—Ç: {filename}\n"
                full_text += f"–°—Ç—Ä–∞–Ω–∏—Ü —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {len(page_texts)} –∏–∑ {total_pages}\n"
                full_text += "---\n\n"
                full_text += "\n\n".join(page_texts)
                
                if progress_callback:
                    await progress_callback(
                        f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\n"
                        f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {len(page_texts)}/{total_pages}"
                    )
                
                logger.info(f"PDF —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω: {len(page_texts)}/{total_pages} —Å—Ç—Ä–∞–Ω–∏—Ü")
                return True, new_name, full_text
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è PDF: {e}")
            if progress_callback:
                await progress_callback(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {str(e)}")
        
        return False, new_name, ""

class ImageConverter(FileConverter):
    """–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ Markdown —á–µ—Ä–µ–∑ AI OCR"""
    
    IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.tif', '.webp'}
    
    def __init__(self, ai_interface=None):
        self.ai_interface = ai_interface
    
    def supports(self, filename: str) -> bool:
        ext = os.path.splitext(filename.lower())[1]
        return ext in self.IMAGE_EXTENSIONS and self.ai_interface is not None
    
    async def convert(self, user_id: str,file_bytes: bytes, filename: str, **kwargs) -> Tuple[bool, str, str]:
        """–†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —á–µ—Ä–µ–∑ AI"""
        base, _ = os.path.splitext(filename)
        new_name = f"{base}.txt"
        
        if not self.ai_interface:
            return False, new_name, ""
        
        try:
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            processed_bytes = await self._resize_image_if_needed(file_bytes)
            
            logger.info(f"–†–∞—Å–ø–æ–∑–Ω–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {filename}, —Ä–∞–∑–º–µ—Ä: {len(processed_bytes)} –±–∞–π—Ç")
            
            prompt = (
                "–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–π –í–ï–°–¨ —Ç–µ–∫—Å—Ç –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏. "
                "–í–µ—Ä–Ω–∏ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≤–∫–ª—é—á–∞—è —Ç–∞–±–ª–∏—Ü—ã, —Å–ø–∏—Å–∫–∏ –∏ –≤—Å–µ –¥–µ—Ç–∞–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown. "
                "–ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç, –Ω–∞–ø–∏—à–∏ —Ç–æ–ª—å–∫–æ: '–¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω'"
            )
            
            result = await self.ai_interface.process_image(user_id,processed_bytes, prompt)
            
            if result:
                result_text = result.strip()
                if result_text and "–¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω" not in result_text and "—Ç–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω" not in result_text.lower():
                    logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ, –ø–æ–ª—É—á–µ–Ω–æ {len(result_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                    return True, new_name, result_text
                else:
                    logger.info("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞")
                    return False, new_name, ""
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ AI —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        
        return False, new_name, ""
    
    async def _resize_image_if_needed(self, image_bytes: bytes, max_dimension: int = 2000) -> bytes:
        """–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –æ–Ω–æ –±–æ–ª—å—à–µ max_dimension"""
        try:
            img = Image.open(BytesIO(image_bytes))
            width, height = img.size
        
            if width <= max_dimension and height <= max_dimension:
                return image_bytes
        
            if width > height:
                new_width = max_dimension
                new_height = int(height * (max_dimension / width))
            else:
                new_height = max_dimension
                new_width = int(width * (max_dimension / height))
        
            logger.info(f"–ú–∞—Å—à—Ç–∞–±–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å {width}x{height} –¥–æ {new_width}x{new_height}")
        
            resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
            buffer = BytesIO()
            if img.mode in ('L', '1', 'LA', 'RGBA'):
                resized.save(buffer, format='PNG', optimize=True)
            else:
                if resized.mode not in ('RGB', 'CMYK'):
                    resized = resized.convert('RGB')
                resized.save(buffer, format='JPEG', quality=95, optimize=True)
        
            return buffer.getvalue()
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return image_bytes


